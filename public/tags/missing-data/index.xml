<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>missing data | Megha</title>
    <link>/tags/missing-data/</link>
      <atom:link href="/tags/missing-data/index.xml" rel="self" type="application/rss+xml" />
    <description>missing data</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Tue, 23 Jun 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/img/icon-192.png</url>
      <title>missing data</title>
      <link>/tags/missing-data/</link>
    </image>
    
    <item>
      <title>Propensity Score Analysis with Multiply Imputed Data</title>
      <link>/post/mi_ps/</link>
      <pubDate>Tue, 23 Jun 2020 00:00:00 +0000</pubDate>
      <guid>/post/mi_ps/</guid>
      <description>


&lt;p&gt;Work in progress…&lt;/p&gt;
&lt;p&gt;In this post, I walk through steps of running propensity scores when there is missingness in the covariate data. Particularly, I look at multiple imputation and ways to condition on propensity scores estimated on imputed data. The code builds on my earlier &lt;a href=&#34;https://meghapsimatrix.com/post/missing_dat/&#34;&gt;post&lt;/a&gt; that goes over different ways to handle missing data when conducting propensity score analysis.&lt;/p&gt;
&lt;p&gt;When using multiple imputations, &lt;span class=&#34;citation&#34;&gt;Hill (2004)&lt;/span&gt; and &lt;span class=&#34;citation&#34;&gt;Mitra and Reiter (2016)&lt;/span&gt; examined two distinct ways to condition on the propensity scores:&lt;/p&gt;
&lt;div id=&#34;multiple-imputation-across-mi-across&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Multiple Imputation Across (MI Across)&lt;/h2&gt;
&lt;p&gt;This approach involves creating &lt;em&gt;m&lt;/em&gt; imputed datasets and then estimating propensity scores within each of the datasets and then averaging each unit’s &lt;em&gt;m&lt;/em&gt; propensity scores across the &lt;em&gt;m&lt;/em&gt; datasets &lt;span class=&#34;citation&#34;&gt;(Hill 2004)&lt;/span&gt;. Stratification, matching or IPW can be implemented using these averaged propensity scores &lt;span class=&#34;citation&#34;&gt;(Hill 2004)&lt;/span&gt;. Outcome models that include covariates will need to use the weights or strata derived from the averaged propensity scores and the &lt;em&gt;m&lt;/em&gt; sets of covariate values. The weighted regression estimates will then need to be pooled.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;multiple-imputation-within-mi-within&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Multiple Imputation Within (MI Within)&lt;/h2&gt;
&lt;p&gt;This approach involves creating &lt;em&gt;m&lt;/em&gt; imputed datasets and then estimating propensity scores within each of the datasets &lt;span class=&#34;citation&#34;&gt;(Hill 2004)&lt;/span&gt;. Instead of averaging the propensity scores across the datasets, this method entails conditioning on the propensity scores within the datasets and running the outcome analyses within each dataset &lt;span class=&#34;citation&#34;&gt;(Hill 2004)&lt;/span&gt;. The separate regression estimates have to be pooled.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;read-in-the-data&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Read in the data&lt;/h1&gt;
&lt;p&gt;Below, I show how to implement the Across and Within methods to estimate the ATT. The data that I use here is from High School and Beyond (HSB) longitudinal study used by &lt;span class=&#34;citation&#34;&gt;Rosenbaum (1986)&lt;/span&gt; to analyze the effect of dropping out of high school on later math achievement.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(mice)
library(twang)
library(estimatr)
library(broom)
library(naniar)
library(knitr)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;hsls_dat &amp;lt;- read_csv(&amp;quot;https://raw.githubusercontent.com/meghapsimatrix/datasets/master/causal/HSLS09_incomplete.csv&amp;quot;) %&amp;gt;%
  mutate_if(is.character, as.factor) %&amp;gt;%
  mutate_at(vars(repeated_grade, IEP), as.factor) %&amp;gt;%
  select(-working_T3) # an outcome we don&amp;#39;t care about&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Below, using &lt;code&gt;gg_miss_var&lt;/code&gt; from the &lt;code&gt;naniar&lt;/code&gt; package, I visualize the percent of data that are missing for each of the variables &lt;span class=&#34;citation&#34;&gt;(Tierney et al. 2020)&lt;/span&gt;. The treatment variable, &lt;code&gt;drop_status&lt;/code&gt; has no missing data. The outcome variable, &lt;code&gt;math_score_T2&lt;/code&gt;, however, does have around 10% missing data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gg_miss_var(hsls_dat, show_pct = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/mi_ps_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;multiple-imputation-using-mice&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Multiple imputation using &lt;code&gt;mice&lt;/code&gt;&lt;/h1&gt;
&lt;p&gt;Here, I impute the data using the &lt;code&gt;mice&lt;/code&gt; package and set the number of imputations and itereations to 10 each and also set the seed &lt;span class=&#34;citation&#34;&gt;(van Buuren and Groothuis-Oudshoorn 2011)&lt;/span&gt;. Then, I save the result as an &lt;code&gt;RData&lt;/code&gt; file. For imputation method, I let mice run the default methods: predicitive mean matching for continuous variables, Bayesian logistic regression for binary variables and Bayesian polytomous regression for multinomial variables. For more information on methods for imputation, please see &lt;a href=&#34;https://stefvanbuuren.name/fimd/sec-modelform.html&#34;&gt;Chapter 6.2&lt;/a&gt; from &lt;a href=&#34;https://stefvanbuuren.name/fimd/&#34;&gt;Flexible Modeling of Missing Data&lt;/a&gt; &lt;span class=&#34;citation&#34;&gt;(van Buuren 2018)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;system.time(temp_data &amp;lt;- mice(hsls_dat, m = 10, maxit = 10, seed = 20200516))

save(temp_data, file = &amp;quot;temp_data.RData&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;long-format-and-propensity-score-model&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Long format and propensity score model&lt;/h1&gt;
&lt;p&gt;I then load the saved RData file and then extract a long format data that contains each of the 10 imputed data stacked.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;load(&amp;quot;temp_data.RData&amp;quot;)
imp_dat &amp;lt;- complete(temp_data, action = &amp;quot;long&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;function-to-estimate-propensity-scores&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Function to estimate propensity scores&lt;/h1&gt;
&lt;p&gt;Below I create a dataset with only the covariates and use the &lt;code&gt;paste()&lt;/code&gt; function to create propensity score model equation. For the sake of this example, I only focus on including main effects of the covariates in the propensity score model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;covs &amp;lt;- imp_dat %&amp;gt;%
  select(sex:climate, math_score_T1)

equation_ps &amp;lt;- paste(&amp;quot;drop_status ~ &amp;quot;, paste(names(covs), collapse = &amp;quot; + &amp;quot;))
equation_ps&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;drop_status ~  sex + race + language + repeated_grade + IEP + locale + region + SES + math_identity + math_utility + math_efficacy + math_interest + engagement + belonging + expectations + climate + math_score_T1&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here, I create a function &lt;code&gt;estimate_ps()&lt;/code&gt; that takes in an equation and a dataset, then runs logistic regression using &lt;code&gt;glm()&lt;/code&gt;. Then the function adds logit of propensity scores and propensity scores as columns in the dataset.&lt;/p&gt;
&lt;p&gt;I then group the &lt;code&gt;imp_dat&lt;/code&gt; by the imputation number and then run the &lt;code&gt;estimate_ps()&lt;/code&gt; function on each of the imputed dataset using the &lt;code&gt;do()&lt;/code&gt; function from &lt;code&gt;dplyr&lt;/code&gt; &lt;span class=&#34;citation&#34;&gt;(Wickham et al. 2019)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;estimate_ps &amp;lt;- function(equation, dat){
  
  ps_model &amp;lt;- glm(as.formula(equation), family = binomial, data = dat)
  
  dat &amp;lt;- dat %&amp;gt;%
    mutate(ps_logit = predict(ps_model, type = &amp;quot;link&amp;quot;),
           ps = predict(ps_model, type = &amp;quot;response&amp;quot;))
  
  return(dat)
  
}


imp_dat_ps &amp;lt;- imp_dat %&amp;gt;%
  group_by(.imp) %&amp;gt;%
  do(estimate_ps(equation_ps, .)) %&amp;gt;%
  ungroup()&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;estimating-weights-using-the-across-and-within-methods&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Estimating weights using the across and within methods&lt;/h1&gt;
&lt;p&gt;Below I estimate ATT weights using the across and within methods. For the Across method, I use the average of the propensity scores across the imputed datasets to calculate weights. For the within method, I use the the propensity scores estimated within each imputed dataset to calculate weights.&lt;/p&gt;
&lt;p&gt;The code below groups the imputed data by &lt;code&gt;.id&lt;/code&gt; which is an identifier denoting each case. For each case, I summarize the mean of the propensity scores across the 10 imputed dataset. I then estimate the ATT weights using the averaged propensity scores for the Across method and the original propensity scores for the Within method.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;imp_dat_ps &amp;lt;- imp_dat_ps %&amp;gt;%
  group_by(.id) %&amp;gt;%
  mutate(ps_across = mean(ps)) %&amp;gt;%
  ungroup() %&amp;gt;%
  mutate(att_wt_across = drop_status + (1 - drop_status) * ps_across/(1 - ps_across),
         att_wt_within = drop_status + (1 - drop_status) * ps/(1 - ps))


imp_dat_ps %&amp;gt;%
  select(.imp, ps, ps_across, att_wt_across, att_wt_within)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 214,020 x 5
##     .imp       ps ps_across att_wt_across att_wt_within
##    &amp;lt;int&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;         &amp;lt;dbl&amp;gt;         &amp;lt;dbl&amp;gt;
##  1     1 0.00339   0.00330       0.00331       0.00340 
##  2     1 0.00989   0.0102        0.0103        0.00999 
##  3     1 0.00135   0.00131       0.00132       0.00135 
##  4     1 0.0119    0.0114        0.0115        0.0120  
##  5     1 0.00222   0.00246       0.00246       0.00222 
##  6     1 0.00289   0.00294       0.00295       0.00290 
##  7     1 0.0113    0.0101        0.0102        0.0114  
##  8     1 0.00347   0.00375       0.00377       0.00348 
##  9     1 0.00327   0.00276       0.00276       0.00328 
## 10     1 0.000667  0.000633      0.000633      0.000667
## # … with 214,010 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;check-balance&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Check balance&lt;/h1&gt;
&lt;/div&gt;
&lt;div id=&#34;estimate-att-for-across-and-within-methods&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Estimate ATT for across and within methods&lt;/h1&gt;
&lt;p&gt;Below I create a function to estimate the ATT. The function takes in an equation, a dataset, and weights as arguments. Then it runs a model using &lt;code&gt;lm_robust()&lt;/code&gt; from the &lt;code&gt;estimatr&lt;/code&gt; package &lt;span class=&#34;citation&#34;&gt;(Blair et al. 2020)&lt;/span&gt;. The standard errors of the regression coefficients are estimated using &lt;code&gt;HC2&lt;/code&gt; type sandwich errors. I then clean up the results using &lt;code&gt;tidy()&lt;/code&gt; from &lt;code&gt;broom&lt;/code&gt; &lt;span class=&#34;citation&#34;&gt;(Robinson and Hayes 2020)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;estimate_ATT &amp;lt;- function(equation, dat, wts){
  
  wts &amp;lt;- dat %&amp;gt;% pull({{wts}})
  
  model &amp;lt;- lm_robust(as.formula(equation), data = dat, weights = wts)
  
  res &amp;lt;- model %&amp;gt;%
    tidy() %&amp;gt;%
    filter(term == &amp;quot;drop_status&amp;quot;) %&amp;gt;%
    select(term, estimate, se = std.error, dci_low = conf.low, ci_high = conf.high, df = df)
  
  return(res)
  
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I set up an equation regressing the outcome variable, &lt;code&gt;math_score_T2&lt;/code&gt; on drop status and on the main effects of all the covariates. I then run the &lt;code&gt;estimate_ATT()&lt;/code&gt; function on each imputed data using &lt;code&gt;group_by()&lt;/code&gt; and &lt;code&gt;do()&lt;/code&gt;. The weights are different for the Across and Within methods.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;equation_ancova &amp;lt;- paste(&amp;quot;math_score_T2 ~ drop_status + &amp;quot;, paste(names(covs), collapse = &amp;quot; + &amp;quot;))
equation_ancova&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;math_score_T2 ~ drop_status +  sex + race + language + repeated_grade + IEP + locale + region + SES + math_identity + math_utility + math_efficacy + math_interest + engagement + belonging + expectations + climate + math_score_T1&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;across_res &amp;lt;- imp_dat_ps %&amp;gt;%
  group_by(.imp) %&amp;gt;%
  do(estimate_ATT(equation = equation_ancova, dat = ., wts = att_wt_across)) %&amp;gt;%
  ungroup()

within_res &amp;lt;- imp_dat_ps %&amp;gt;%
  group_by(.imp) %&amp;gt;%
  do(estimate_ATT(equation = equation_ancova, dat = ., wts = att_wt_within)) %&amp;gt;%
  ungroup()&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;pool-the-results&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Pool the results&lt;/h1&gt;
&lt;p&gt;Here, I create a function called &lt;code&gt;calc_pooled()&lt;/code&gt; using formula by &lt;span class=&#34;citation&#34;&gt;Barnard and Rubin (n.d.)&lt;/span&gt; to pool the results across the imputations. The &lt;code&gt;mice&lt;/code&gt; package has the &lt;code&gt;pool()&lt;/code&gt; function to do the same thing but we would need to convert the imputed data back to &lt;code&gt;mids&lt;/code&gt; object type and I just wanted to skip all that :D&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;calc_pooled &amp;lt;- function(dat, est, se, df){
  
  dat &amp;lt;- dat %&amp;gt;%
    mutate(est = dat %&amp;gt;% pull({{est}}),
           se = dat %&amp;gt;%pull({{se}}),
           df = dat %&amp;gt;% pull({{df}}))
  
  pooled &amp;lt;- dat %&amp;gt;%
    summarize(m = n(),
              B = var(est),  # between imputation var
              beta_bar = mean(est), # mean of estimated reg coeffs
              V_bar = mean(se^2), # mean of var - hc corrected   within imp var
              eta_bar = mean(df)) %&amp;gt;%   # mean of df
    mutate(
      
      V_total = V_bar + B * (m + 1) / m,  #between and within var est
      gamma = ((m + 1) / m) * B / V_total,  
      df_m = (m - 1) / gamma^2,
      df_obs = eta_bar * (eta_bar + 1) * (1 - gamma) / (eta_bar + 3),
      df = 1 / (1 / df_m + 1 / df_obs),
      
      # output
      se = sqrt(V_total),
      ci_lower = beta_bar - se * qt(0.975, df = df),
      ci_upper = beta_bar + se * qt(0.975, df = df)) %&amp;gt;%
    
    select(est = beta_bar, se, df, ci_lower, ci_upper) 
  
  return(pooled)
  
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;pooling&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Pooling&lt;/h1&gt;
&lt;p&gt;Below I use the &lt;code&gt;calc_pooled()&lt;/code&gt; function to pool the results for each of the methods.&lt;/p&gt;
&lt;div id=&#34;across&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Across&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;across_pooled &amp;lt;- calc_pooled(dat = across_res, est = estimate, se = se, df = df)
across_pooled %&amp;gt;%
  kable(digits = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;right&#34;&gt;est&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;se&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;df&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;ci_lower&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;ci_upper&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;-0.335&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.038&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;93.772&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.411&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.26&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;within&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Within&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;within_pooled &amp;lt;- calc_pooled(dat = within_res, est = estimate, se = se, df = df)
within_pooled %&amp;gt;%
  kable(digits = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;right&#34;&gt;est&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;se&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;df&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;ci_lower&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;ci_upper&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;-0.356&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.041&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;50.002&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.438&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.273&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The estimates, se and df are different for the results from the two different methods.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;which-one-to-use&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Which one to use?&lt;/h1&gt;
&lt;p&gt;&lt;span class=&#34;citation&#34;&gt;Hill (2004)&lt;/span&gt; and &lt;span class=&#34;citation&#34;&gt;Mitra and Reiter (2016)&lt;/span&gt; conducted simulation studies comparing the two methods. &lt;span class=&#34;citation&#34;&gt;Hill (2004)&lt;/span&gt; found that MI Across performed best in terms of absolute bias and mean squared error compared to all the other methods examined in the study. &lt;span class=&#34;citation&#34;&gt;Mitra and Reiter (2016)&lt;/span&gt; found that MI Across resulted in greater bias reduction in the estimation of ATT compared to MI Within. For details of the simulation studies please see the articles.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references&#34;&gt;
&lt;div id=&#34;ref-barnard_small-sample_nodate&#34;&gt;
&lt;p&gt;Barnard, John, and Donald B Rubin. n.d. “Small-Sample Degrees of Freedom with Multiple Imputation,” 9.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-estimatr_2020&#34;&gt;
&lt;p&gt;Blair, Graeme, Jasper Cooper, Alexander Coppock, Macartan Humphreys, and Luke Sonnet. 2020. &lt;em&gt;Estimatr: Fast Estimators for Design-Based Inference&lt;/em&gt;. &lt;a href=&#34;https://CRAN.R-project.org/package=estimatr&#34;&gt;https://CRAN.R-project.org/package=estimatr&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-hill_2004&#34;&gt;
&lt;p&gt;Hill, Jennifer. 2004. “Reducing Bias in Treatment Effect Estimation in Observational Studies Suffering from Missing Data.” Columbia University Institute for Social &amp;amp; Economic Research &amp;amp; Policy (ISERP).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-mitra_comparison_2016&#34;&gt;
&lt;p&gt;Mitra, Robin, and Jerome P Reiter. 2016. “A Comparison of Two Methods of Estimating Propensity Scores After Multiple Imputation.” &lt;em&gt;Statistical Methods in Medical Research&lt;/em&gt; 25 (1): 188–204. &lt;a href=&#34;https://doi.org/10.1177/0962280212445945&#34;&gt;https://doi.org/10.1177/0962280212445945&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-broom_2020&#34;&gt;
&lt;p&gt;Robinson, David, and Alex Hayes. 2020. &lt;em&gt;Broom: Convert Statistical Analysis Objects into Tidy Tibbles&lt;/em&gt;. &lt;a href=&#34;https://CRAN.R-project.org/package=broom&#34;&gt;https://CRAN.R-project.org/package=broom&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-rosenbaum1986dropping&#34;&gt;
&lt;p&gt;Rosenbaum, Paul R. 1986. “Dropping Out of High School in the United States: An Observational Study.” &lt;em&gt;Journal of Educational Statistics&lt;/em&gt; 11 (3). Sage Publications Sage CA: Los Angeles, CA: 207–24.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-naniar_2020&#34;&gt;
&lt;p&gt;Tierney, Nicholas, Di Cook, Miles McBain, and Colin Fay. 2020. &lt;em&gt;Naniar: Data Structures, Summaries, and Visualisations for Missing Data&lt;/em&gt;. &lt;a href=&#34;https://CRAN.R-project.org/package=naniar&#34;&gt;https://CRAN.R-project.org/package=naniar&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-van2018flexible&#34;&gt;
&lt;p&gt;van Buuren, Stef. 2018. &lt;em&gt;Flexible Imputation of Missing Data&lt;/em&gt;. Chapman; Hall/CRC.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-vanB_2011&#34;&gt;
&lt;p&gt;van Buuren, Stef, and Karin Groothuis-Oudshoorn. 2011. “mice: Multivariate Imputation by Chained Equations in R.” &lt;em&gt;Journal of Statistical Software&lt;/em&gt; 45 (3): 1–67. &lt;a href=&#34;http://www.jstatsoft.org/v45/i03/&#34;&gt;http://www.jstatsoft.org/v45/i03/&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-tidy_2020&#34;&gt;
&lt;p&gt;Wickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy D’Agostino McGowan, Romain François, Garrett Grolemund, et al. 2019. “Welcome to the tidyverse.” &lt;em&gt;Journal of Open Source Software&lt;/em&gt; 4 (43): 1686. &lt;a href=&#34;https://doi.org/10.21105/joss.01686&#34;&gt;https://doi.org/10.21105/joss.01686&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Missing Data in Propensity Score Analysis</title>
      <link>/post/missing_dat/</link>
      <pubDate>Thu, 16 Apr 2020 00:00:00 +0000</pubDate>
      <guid>/post/missing_dat/</guid>
      <description>


&lt;p&gt;Theories behind propensity score analysis assume that the covariates are fully observed &lt;span class=&#34;citation&#34;&gt;(Rosenbaum &amp;amp; Rubin, 1983, 1984)&lt;/span&gt;. However, in practice, observational analyses require large administrative databases or surveys, which inevitably will have missingness in the covariates. The response patterns of people with missing covariates may be different than those of people with observed data &lt;span class=&#34;citation&#34;&gt;(Mohan, Pearl, &amp;amp; Tian, 2013)&lt;/span&gt;. Therefore, ways to handle missing covariate data need to be examined. The basic estimation of propensity scores using logistic regression will delete cases with missing data, which can be problematic as it can cause bias in the treatment effect estimates &lt;span class=&#34;citation&#34;&gt;(Baraldi &amp;amp; Enders, 2010)&lt;/span&gt;.&lt;/p&gt;
&lt;div id=&#34;missing-data-methods-in-propensity-score-analysis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Missing Data Methods in Propensity Score Analysis&lt;/h2&gt;
&lt;p&gt;Below I explain three major methods used in the applied propensity score analysis literature when &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; is not fully observed. I also explain three other methods to handle missing data that are not commonly used in applied literature but have been proposed theoretically. I also describe the assumptions about missing data and strong ignorability underlying each of the methods. Let &lt;span class=&#34;math inline&#34;&gt;\(X_{obs}\)&lt;/span&gt; indicate the observed parts of &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(X_{mis}\)&lt;/span&gt; indicate the missing parts of &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;. &lt;span class=&#34;math inline&#34;&gt;\(D\)&lt;/span&gt; indicates the fully observed treatment indicator and &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; indicates a fully observed outcome variable.&lt;/p&gt;
&lt;div id=&#34;complete-case-analysis&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Complete Case Analysis&lt;/h3&gt;
&lt;p&gt;This approach deletes cases with missing data in any of the variables used in the analysis &lt;span class=&#34;citation&#34;&gt;(Baraldi &amp;amp; Enders, 2010; Hill, 2004)&lt;/span&gt;. The traditional propensity score estimation method of using logistic regression implements complete case analysis by default. Therefore, this method is commonly used in applied research. The data that remains after deleting cases with missing data are assumed to be a simple random sample of the full data &lt;span class=&#34;citation&#34;&gt;(Baraldi &amp;amp; Enders, 2010)&lt;/span&gt;. Missingness is not related to any study variables nor to the hypothetically complete values of itself (Equations  and ). According to &lt;span class=&#34;citation&#34;&gt;Hill (2004)&lt;/span&gt;, the assumption underlying complete case analysis is that the joint distributions of &lt;span class=&#34;math inline&#34;&gt;\(X_{obs}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(X_{mis}\)&lt;/span&gt; are same across the two treatment conditions:
&lt;span class=&#34;math display&#34;&gt;\[\begin{equation}
X_{obs}, X_{mis} \perp\!\!\!\perp D
\end{equation}\]&lt;/span&gt;
Therefore, an unbiased causal effect estimate can be retrieved after deleting cases with missing data. Such an assumption is very stringent and unlikely to be met in the types of data required for propensity score analyses &lt;span class=&#34;citation&#34;&gt;(Baraldi &amp;amp; Enders, 2010; Hill, 2004)&lt;/span&gt;. As mentioned above, deleting cases can also result in loss of power. Additionally, whether &lt;span class=&#34;math inline&#34;&gt;\(X_{mis}\)&lt;/span&gt; is balanced between the treatment groups cannot be confirmed.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;multiple-imputation&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Multiple Imputation&lt;/h3&gt;
&lt;p&gt;Multiple imputation (MI) generates multiple sets of data with the missing values drawn from an imputation model &lt;span class=&#34;citation&#34;&gt;(Mitra &amp;amp; Reiter, 2016; Rubin, 1987)&lt;/span&gt;. MI will create &lt;span class=&#34;math inline&#34;&gt;\(m &amp;gt; 1\)&lt;/span&gt; imputed datasets that contain different imputed values &lt;span class=&#34;citation&#34;&gt;(Murray, 2018; van Buuren, 2018)&lt;/span&gt;. Analyses can be performed on each of the datasets and results from each dataset can be aggregated across to derive a final estimate, standard error, degrees of freedom, and test result. Thus, MI involves two stages: (1) imputation and creation of the &lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt; imputed datasets, and (2) analysis and pooling of estimates across the datasets &lt;span class=&#34;citation&#34;&gt;(Murray, 2018; van Buuren, 2018)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;There are two approaches for imputing multivariate missing data: (1) joint modeling, JM, and (2) fully conditional specification, FCS, also called multivariate imputation by chained equations, MICE &lt;span class=&#34;citation&#34;&gt;(Murray, 2018; van Buuren, 2018; van Buuren &amp;amp; Groothuis-Oudshoorn, 2011)&lt;/span&gt;. JM entails jointly modeling variables with missingness by drawing from a multivariate distribution &lt;span class=&#34;citation&#34;&gt;(Murray, 2018; van Buuren, 2018; van Buuren &amp;amp; Groothuis-Oudshoorn, 2011)&lt;/span&gt;. FCS entails univariate conditional imputation models of variables with missing data that iteratively condition on all other variables using Monte Carlo Markov chain methods &lt;span class=&#34;citation&#34;&gt;(van Buuren, 2018; van Buuren &amp;amp; Groothuis-Oudshoorn, 2011)&lt;/span&gt;. JM imputes all variables simultaneously whereas FCS imputes one variable at a time &lt;span class=&#34;citation&#34;&gt;(van Buuren, 2018)&lt;/span&gt;. Because JM requires specification of a joint distribution for all the variables, it may not be as flexible as FCS when dealing with a large number of covariates with missing data &lt;span class=&#34;citation&#34;&gt;(Akande, Li, &amp;amp; Reiter, 2017)&lt;/span&gt;. However, FCS is computationally more intensive than JM &lt;span class=&#34;citation&#34;&gt;(van Buuren, 2018)&lt;/span&gt;. FCS also has been shown to outperform JM for categorical variables and is more robust under mis-specification of imputation model &lt;span class=&#34;citation&#34;&gt;(van Buuren, 2018)&lt;/span&gt;. Therefore, &lt;span class=&#34;citation&#34;&gt;van Buuren (2018)&lt;/span&gt; recommended to use FCS over JM.&lt;/p&gt;
&lt;p&gt;If the missingness mechanism is MAR or MCAR and if assumptions underlying the imputation model are correct, MI will yield unbiased results, as it uses the information available in &lt;span class=&#34;math inline&#34;&gt;\(X_{obs}\)&lt;/span&gt; to impute missing values &lt;span class=&#34;citation&#34;&gt;(Murray, 2018)&lt;/span&gt;. In the causal inference context, &lt;span class=&#34;citation&#34;&gt;Hill (2004)&lt;/span&gt; argued that MI relies on the assumption of &lt;em&gt;latent ignorability&lt;/em&gt;, a concept introduced by &lt;span class=&#34;citation&#34;&gt;Frangakis &amp;amp; Rubin (1999)&lt;/span&gt;. The assumption requires that the treatment assignment mechanism is ignorable given complete covariate data including the values that are latent or missing. These missing values are derived from MI. Below, let &lt;span class=&#34;math inline&#34;&gt;\(e_{MI}(X)\)&lt;/span&gt; denote propensity scores derived after multiple imputation:
&lt;span class=&#34;math display&#34;&gt;\[\begin{equation}
X_{obs}, X_{mis} \perp\!\!\!\perp D| e_{MI}(X)
\end{equation}\]&lt;/span&gt;
&lt;span class=&#34;math display&#34;&gt;\[\begin{equation}
Y(1), Y(0) \perp\!\!\!\perp D | e_{MI}(X)
\end{equation}\]&lt;/span&gt;
&lt;span class=&#34;citation&#34;&gt;Hill (2004)&lt;/span&gt; proposed two different ways to combine propensity scores estimated in each of the &lt;em&gt;m&lt;/em&gt; datasets:&lt;/p&gt;
&lt;div id=&#34;multiple-imputation-across-mi-across&#34; class=&#34;section level5&#34;&gt;
&lt;h5&gt;Multiple Imputation Across (MI Across)&lt;/h5&gt;
&lt;p&gt;This approach involves creating &lt;em&gt;m&lt;/em&gt; imputed datasets and then estimating propensity scores within each of the datasets and then averaging each unit’s &lt;em&gt;m&lt;/em&gt; propensity scores across the &lt;em&gt;m&lt;/em&gt; datasets &lt;span class=&#34;citation&#34;&gt;(Hill, 2004)&lt;/span&gt;. Stratification, matching or IPW can be implemented using these averaged propensity scores &lt;span class=&#34;citation&#34;&gt;(Hill, 2004)&lt;/span&gt;. Outcome models that include covariates will need to use the weights or strata derived from the averaged propensity scores and the &lt;em&gt;m&lt;/em&gt; sets of covariate values. The weighted regression estimates will then need to be pooled.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;multiple-imputation-within-mi-within&#34; class=&#34;section level5&#34;&gt;
&lt;h5&gt;Multiple Imputation Within (MI Within)&lt;/h5&gt;
&lt;p&gt;This approach involves creating &lt;em&gt;m&lt;/em&gt; imputed datasets and then estimating propensity scores within each of the datasets &lt;span class=&#34;citation&#34;&gt;(Hill, 2004)&lt;/span&gt;. Instead of averaging the propensity scores across the datasets, this method entails conditioning on the propensity scores within the datasets and running the outcome analyses within each dataset &lt;span class=&#34;citation&#34;&gt;(Hill, 2004)&lt;/span&gt;. The separate regression estimates have to be pooled.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;generalized-propensity-scores&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Generalized Propensity Scores&lt;/h3&gt;
&lt;p&gt;&lt;span class=&#34;citation&#34;&gt;Rosenbaum &amp;amp; Rubin (1984)&lt;/span&gt; proposed the use of generalized propensity scores (GPS) as a way to address missing covariate data. The GPS represents the probability of treatment given observed covariates and missingness indicators &lt;span class=&#34;citation&#34;&gt;(Rosenbaum &amp;amp; Rubin, 1984)&lt;/span&gt;:
&lt;span class=&#34;math display&#34;&gt;\[\begin{equation}
e^*(X) = P(D = 1|X_{obs}, R)
\end{equation}\]&lt;/span&gt;
Conditioning on &lt;span class=&#34;math inline&#34;&gt;\(e^*(X)\)&lt;/span&gt; will balance the treatment groups in terms of the observed covariates and missingness patterns &lt;span class=&#34;citation&#34;&gt;(Rosenbaum &amp;amp; Rubin, 1984)&lt;/span&gt;. The observed part of &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; and the missingness pattern indicators, &lt;span class=&#34;math inline&#34;&gt;\(R\)&lt;/span&gt;, will be independent of treatment assignment given the GPS &lt;span class=&#34;citation&#34;&gt;(Rosenbaum &amp;amp; Rubin, 1984)&lt;/span&gt;:
&lt;span class=&#34;math display&#34;&gt;\[\begin{equation}
X_{obs}, R \perp\!\!\!\perp D| e^*(X)
\end{equation}\]&lt;/span&gt;
However, conditioning on GPS will not balance the groups in terms of the unobserved values of &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; &lt;span class=&#34;citation&#34;&gt;(Rosenbaum &amp;amp; Rubin, 1984)&lt;/span&gt;:
&lt;span class=&#34;math display&#34;&gt;\[\begin{equation}
X_{mis} \not\!\perp\!\!\!\perp D| e^*(X)
\end{equation}\]&lt;/span&gt;
Although this technique of treating missing data is not generally recommended for other types of missing data analyses, it has been recommended for use in propensity score analysis literature &lt;span class=&#34;citation&#34;&gt;(Rosenbaum &amp;amp; Rubin, 1984; Stuart, 2010)&lt;/span&gt;. In the context of propensity score analysis, this approach does not assume latent ignorability of treatment assignment because legitimate values for missing data are never derived. The assumption underlying this method is that balancing the treatment and control groups on &lt;span class=&#34;math inline&#34;&gt;\(X_{obs}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(R\)&lt;/span&gt; is a sufficient condition to satisfy ignorability. With the GPS, the treatment and control groups are possibly not going to be balanced in terms of &lt;span class=&#34;math inline&#34;&gt;\(X_{mis}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;For large studies with few missing data patterns, &lt;span class=&#34;citation&#34;&gt;Rosenbaum &amp;amp; Rubin (1984)&lt;/span&gt; suggested estimating separate logit models for each missingness pattern. In practice, it is common to encounter many patterns of missing data. For these scenarios, &lt;span class=&#34;citation&#34;&gt;Rosenbaum &amp;amp; Rubin (1984)&lt;/span&gt; suggested creating an additional category indicating missingness for categorical variables. For continuous variables, &lt;span class=&#34;citation&#34;&gt;Stuart (2010)&lt;/span&gt; recommended imputing missing data with a single arbitrary value, such as the overall mean of the covariate, and then creating a missingness indicator variable. In general missing data analysis context, &lt;span class=&#34;citation&#34;&gt;van Buuren (2018)&lt;/span&gt; noted that this method of combining arbitrary (mean) imputation along with missingness indicators can underestimate the standard error of the estimate of interest.&lt;/p&gt;
&lt;p&gt;The CART algorithms treat missing data natively as they split missingness as a category itself. In this manner, this approach is similar to the GPS which uses missingness pattern indicators when estimating propensity scores. The missingness categories are used to estimate propensity scores and conditioning on the propensity scores should balance the treatment and control condition in terms of the patterns. However, splitting does not actually impute the missing data so it is plausible to assume that like GPS, scores derived using the splitting method will not balance the groups in terms of the latent missing data. In addition, unlike MI, there are no imputed complete datasets saved to analyze for the outcome model. Therefore, splitting would need to be combined with some other technique for outcome modeling.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;other-methods&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Other Methods&lt;/h3&gt;
&lt;p&gt;The following methods have been discussed theoretically in literature examining missing data methods in propensity score analysis. However, these methods are not commonly used in applied literature.&lt;/p&gt;
&lt;div id=&#34;complete-variables&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Complete Variables&lt;/h4&gt;
&lt;p&gt;This method removes any variable with missing data &lt;span class=&#34;citation&#34;&gt;(Hill, 2004)&lt;/span&gt;. By removing variables with missing data, the approach assumes that the distribution of those variables (both the observed and missing parts) are the same across the two treatment groups &lt;span class=&#34;citation&#34;&gt;(Hill, 2004)&lt;/span&gt;. If this assumption does not hold, then this method can result in bias in treatment effect estimates due to removal of important confounding variables &lt;span class=&#34;citation&#34;&gt;(Hill, 2004)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;dagostino-and-rubin-expectation-maximization&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;D’Agostino and Rubin Expectation Maximization&lt;/h4&gt;
&lt;p&gt;Another approach is a method introduced by &lt;span class=&#34;citation&#34;&gt;D’Agostino &amp;amp; Rubin (2000)&lt;/span&gt;, which estimates propensity scores using an Expectation Conditional Maximization (ECM) algorithm &lt;span class=&#34;citation&#34;&gt;(Hill, 2004)&lt;/span&gt;. This method, DR, works similar to GPS as it models &lt;span class=&#34;math inline&#34;&gt;\(X_{obs}\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(R\)&lt;/span&gt;, and the treatment indicator variable. However, instead of imputing &lt;span class=&#34;math inline&#34;&gt;\(X_{mis}\)&lt;/span&gt;, the DR method uses ECM to estimate propensity scores in presence of missing data &lt;span class=&#34;citation&#34;&gt;(Hill, 2004)&lt;/span&gt;. The assumption underlying DR is that within each missingness pattern defined by &lt;span class=&#34;math inline&#34;&gt;\(R\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(X_{mis}\)&lt;/span&gt; is independent of &lt;span class=&#34;math inline&#34;&gt;\(D\)&lt;/span&gt; given the observed data, &lt;span class=&#34;math inline&#34;&gt;\(X_{obs}\)&lt;/span&gt; &lt;span class=&#34;citation&#34;&gt;(Hill, 2004)&lt;/span&gt;:
&lt;span class=&#34;math display&#34;&gt;\[\begin{equation}
X_{mis} \perp\!\!\!\perp D| X_{obs}, R
\end{equation}\]&lt;/span&gt;
Such independence is sufficient to satisfy the ignorability assumption in presence of missing covariate data. With this method, the assumption cannot be checked, however, as DR does not actually impute the missing values. This method is not readily available in commonly used software like R.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;multiple-imputation-missingness-indicator-pattern-mixutre&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Multiple Imputation Missingness Indicator Pattern Mixutre&lt;/h4&gt;
&lt;p&gt;&lt;span class=&#34;citation&#34;&gt;Qu &amp;amp; Lipkovich (2009)&lt;/span&gt; extended MI by introducing the missingness indicator pattern mixture (MIMP) approach, which is the same as MI but adds &lt;span class=&#34;math inline&#34;&gt;\(R\)&lt;/span&gt; in the propensity score estimation model. The rationale behind this approach is to use information given by missingness patterns to estimate treatment propensities. The method will assume latent ignorabilty. However, this approach should also balance the treatment group on &lt;span class=&#34;math inline&#34;&gt;\(R\)&lt;/span&gt; as &lt;span class=&#34;math inline&#34;&gt;\(R\)&lt;/span&gt; is used to estimate the propensity scores:
&lt;span class=&#34;math display&#34;&gt;\[\begin{equation}
X_{obs}, X_{mis}, R \perp\!\!\!\perp D| e_{MIMP}(X)
\end{equation}\]&lt;/span&gt;
&lt;span class=&#34;citation&#34;&gt;Qu &amp;amp; Lipkovich (2009)&lt;/span&gt; argued that extending MI by adding R to the propensity score estimation accounts for non-ignorability or MNAR &lt;span class=&#34;citation&#34;&gt;(Qu &amp;amp; Lipkovich, 2009; van Buuren, 2018)&lt;/span&gt;. This method allows missingness itself to provide information on missingness:
&lt;span class=&#34;math display&#34;&gt;\[\begin{equation}
P(X| X_{obs}, R = 1) \neq P(X| X_{obs}, R = 0)
\end{equation}\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references&#34;&gt;
&lt;div id=&#34;ref-akande2017empirical&#34;&gt;
&lt;p&gt;Akande, O., Li, F., &amp;amp; Reiter, J. (2017). An empirical comparison of multiple imputation methods for categorical data. &lt;em&gt;The American Statistician&lt;/em&gt;, &lt;em&gt;71&lt;/em&gt;(2), 162–170.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-baraldi_introduction_2010&#34;&gt;
&lt;p&gt;Baraldi, A. N., &amp;amp; Enders, C. K. (2010). An introduction to modern missing data analyses. &lt;em&gt;Journal of School Psychology&lt;/em&gt;, &lt;em&gt;48&lt;/em&gt;(1), 5–37. &lt;a href=&#34;https://doi.org/10.1016/j.jsp.2009.10.001&#34;&gt;https://doi.org/10.1016/j.jsp.2009.10.001&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-dagostino_estimating_2000&#34;&gt;
&lt;p&gt;D’Agostino, R. B., &amp;amp; Rubin, D. B. (2000). Estimating and Using Propensity Scores with Partially Missing Data. &lt;em&gt;Journal of the American Statistical Association&lt;/em&gt;, &lt;em&gt;95&lt;/em&gt;(451), 749. &lt;a href=&#34;https://doi.org/10.2307/2669455&#34;&gt;https://doi.org/10.2307/2669455&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-frangakis_addressing_1999&#34;&gt;
&lt;p&gt;Frangakis, C., &amp;amp; Rubin, D. B. (1999). Addressing complications of intention-to-treat analysis in the combined presence of all-or-none treatment-noncompliance and subsequent missing outcomes. &lt;em&gt;Biometrika&lt;/em&gt;, &lt;em&gt;86&lt;/em&gt;(2), 365–379. &lt;a href=&#34;https://doi.org/10.1093/biomet/86.2.365&#34;&gt;https://doi.org/10.1093/biomet/86.2.365&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-hill_2004&#34;&gt;
&lt;p&gt;Hill, J. (2004). &lt;em&gt;Reducing bias in treatment effect estimation in observational studies suffering from missing data&lt;/em&gt;. Columbia University Institute for Social &amp;amp; Economic Research &amp;amp; Policy (ISERP).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-mitra_comparison_2016&#34;&gt;
&lt;p&gt;Mitra, R., &amp;amp; Reiter, J. P. (2016). A comparison of two methods of estimating propensity scores after multiple imputation. &lt;em&gt;Statistical Methods in Medical Research&lt;/em&gt;, &lt;em&gt;25&lt;/em&gt;(1), 188–204. &lt;a href=&#34;https://doi.org/10.1177/0962280212445945&#34;&gt;https://doi.org/10.1177/0962280212445945&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-mohan_graphical_2013&#34;&gt;
&lt;p&gt;Mohan, K., Pearl, J., &amp;amp; Tian, J. (2013). Graphical models for inference with missing data. In C. Burges, L. Bottou, M. Welling, Z. Ghahramani, &amp;amp; K. Q. Weinberger (Eds.), &lt;em&gt;Advances in neural information processing system&lt;/em&gt; (pp. 1277–1285). Red Hook, NY: Curran Associates, Inc.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-murray_multiple_2018&#34;&gt;
&lt;p&gt;Murray, J. S. (2018). Multiple Imputation: A Review of Practical and Theoretical Findings. &lt;em&gt;Statistical Science&lt;/em&gt;, &lt;em&gt;33&lt;/em&gt;(2), 142–159. &lt;a href=&#34;https://doi.org/10.1214/18-STS644&#34;&gt;https://doi.org/10.1214/18-STS644&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-qu_propensity_2009&#34;&gt;
&lt;p&gt;Qu, Y., &amp;amp; Lipkovich, I. (2009). Propensity score estimation with missing values using a multiple imputation missingness pattern (MIMP) approach. &lt;em&gt;Statistics in Medicine&lt;/em&gt;, &lt;em&gt;28&lt;/em&gt;(9), 1402–1414. &lt;a href=&#34;https://doi.org/10.1002/sim.3549&#34;&gt;https://doi.org/10.1002/sim.3549&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-rosenbaum_central_1983&#34;&gt;
&lt;p&gt;Rosenbaum, P. R., &amp;amp; Rubin, D. B. (1983). The Central Role of the Propensity Score in Observational Studies for Causal Effects. &lt;em&gt;Biometrika&lt;/em&gt;, &lt;em&gt;70&lt;/em&gt;(1), 41. &lt;a href=&#34;https://doi.org/10.2307/2335942&#34;&gt;https://doi.org/10.2307/2335942&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-rosenbaum_reducing_1984&#34;&gt;
&lt;p&gt;Rosenbaum, P. R., &amp;amp; Rubin, D. B. (1984). Reducing Bias in Observational Studies Using Subclassification on the Propensity Score. &lt;em&gt;Journal of the American Statistical Association&lt;/em&gt;, &lt;em&gt;79&lt;/em&gt;(387), 516. &lt;a href=&#34;https://doi.org/10.2307/2288398&#34;&gt;https://doi.org/10.2307/2288398&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-rubin_multiple_1987&#34;&gt;
&lt;p&gt;Rubin, D. B. (1987). &lt;em&gt;Multiple imputation for nonresponse in surveys&lt;/em&gt;. New York: Wiley.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-stuart_matching_2010&#34;&gt;
&lt;p&gt;Stuart, E. A. (2010). Matching Methods for Causal Inference: A Review and a Look Forward. &lt;em&gt;Statistical Science&lt;/em&gt;, &lt;em&gt;25&lt;/em&gt;(1), 1–21. &lt;a href=&#34;https://doi.org/10.1214/09-STS313&#34;&gt;https://doi.org/10.1214/09-STS313&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-van2018flexible&#34;&gt;
&lt;p&gt;van Buuren, S. (2018). &lt;em&gt;Flexible imputation of missing data&lt;/em&gt;. Chapman; Hall/CRC.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-vanB_2011&#34;&gt;
&lt;p&gt;van Buuren, S., &amp;amp; Groothuis-Oudshoorn, K. (2011). mice: Multivariate imputation by chained equations in r. &lt;em&gt;Journal of Statistical Software&lt;/em&gt;, &lt;em&gt;45&lt;/em&gt;(3), 1–67. Retrieved from &lt;a href=&#34;http://www.jstatsoft.org/v45/i03/&#34;&gt;http://www.jstatsoft.org/v45/i03/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>The Performance of Multivariate Methods for Two-Group Comparisons with Small Samples and Incomplete Data</title>
      <link>/publication/missingdata/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/publication/missingdata/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;

&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Slides&lt;/em&gt; button above to demo Academic&amp;rsquo;s Markdown slides feature.
  &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Supplementary notes can be added here, including &lt;a href=&#34;https://sourcethemes.com/academic/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34;&gt;code and math&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
