<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ggplot | Megha</title>
    <link>/tags/ggplot/</link>
      <atom:link href="/tags/ggplot/index.xml" rel="self" type="application/rss+xml" />
    <description>ggplot</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Fri, 17 Apr 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/img/icon-192.png</url>
      <title>ggplot</title>
      <link>/tags/ggplot/</link>
    </image>
    
    <item>
      <title>COVID-19</title>
      <link>/post/coronavirus/</link>
      <pubDate>Fri, 17 Apr 2020 00:00:00 +0000</pubDate>
      <guid>/post/coronavirus/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/htmlwidgets/htmlwidgets.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/pymjs/pym.v1.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/widgetframe-binding/widgetframe.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;In this post, I am analyzing data on COVID-19 cases worldwide. The data that I am analyzing only accounts for reported cases. Due to the lack of availability and accessibility of testing in countries like the US, the numbers may be an underestimate of the actual number of cases, number of deaths, and number of recoveries. The data does not account for any other errors of measurement.&lt;/p&gt;
&lt;div id=&#34;libraries&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Libraries&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(CausalImpact)
library(tidyverse)
library(maps)
library(ggthemes)
library(jsonlite)
library(leaflet)
library(widgetframe)
library(lubridate)
library(scales)
library(ggrepel)
library(tidyquant)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;read-in-the-data&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Read in the Data&lt;/h1&gt;
&lt;p&gt;I downloaded the data from &lt;a href=&#34;https://github.com/CSSEGISandData/COVID-19&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;confirmed &amp;lt;- read_csv(&amp;quot;https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv&amp;quot;) %&amp;gt;%
  pivot_longer(cols = -c(1:4),
               names_to = &amp;quot;date&amp;quot;,
               values_to = &amp;quot;confirmed&amp;quot;)

deaths &amp;lt;- read_csv(&amp;quot;https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv&amp;quot;) %&amp;gt;%
  pivot_longer(cols = -c(1:4),
               names_to = &amp;quot;date&amp;quot;,
               values_to = &amp;quot;deaths&amp;quot;)

recovered &amp;lt;- read_csv(&amp;quot;https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv&amp;quot;) %&amp;gt;%
  pivot_longer(cols = -c(1:4),
               names_to = &amp;quot;date&amp;quot;,
               values_to = &amp;quot;recoveries&amp;quot;)

# Join and Clean 
dat &amp;lt;- left_join(confirmed, deaths) %&amp;gt;%
  left_join(recovered) %&amp;gt;%
  mutate(date = mdy(date),
         lab = paste0(&amp;quot;Confirmed: &amp;quot;, confirmed, &amp;quot;, &amp;quot;, &amp;quot;Deaths: &amp;quot;, deaths, &amp;quot;, &amp;quot;, &amp;quot;Recovered: &amp;quot;, recoveries)) %&amp;gt;%
  rename(country_region = `Country/Region`)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;coronavirus-confirmed-cases&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Coronavirus Confirmed Cases&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;covid_leaf &amp;lt;- leaflet(data = dat, 
                      options = leafletOptions(minZoom = 1.5)) %&amp;gt;% 
  addProviderTiles(providers$CartoDB.DarkMatter)  %&amp;gt;%
  addCircleMarkers(~Long, ~Lat, 
                   radius = ~confirmed/10000, 
                   label = ~lab, 
                   fillOpacity = .2)

frameWidget(covid_leaf)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;htmlwidget-1&#34; style=&#34;width:100%;height:480px;&#34; class=&#34;widgetframe html-widget&#34;&gt;&lt;/div&gt;
&lt;script type=&#34;application/json&#34; data-for=&#34;htmlwidget-1&#34;&gt;{&#34;x&#34;:{&#34;url&#34;:&#34;/post/Coronavirus_files/figure-html//widgets/widget_unnamed-chunk-3.html&#34;,&#34;options&#34;:{&#34;xdomain&#34;:&#34;*&#34;,&#34;allowfullscreen&#34;:false,&#34;lazyload&#34;:false}},&#34;evals&#34;:[],&#34;jsHooks&#34;:[]}&lt;/script&gt;
&lt;/div&gt;
&lt;div id=&#34;cases-by-week&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Cases by Week&lt;/h1&gt;
&lt;div id=&#34;confirmed&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Confirmed&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;country_dat &amp;lt;- dat %&amp;gt;%
  filter(country_region %in% c(&amp;quot;China&amp;quot;, &amp;quot;Italy&amp;quot;, &amp;quot;Iran&amp;quot;, &amp;quot;Korea, South&amp;quot;, &amp;quot;Spain&amp;quot;, &amp;quot;US&amp;quot;)) %&amp;gt;%
  mutate(week = cut(date, &amp;quot;week&amp;quot;, start.on.monday = FALSE))

country_dat %&amp;gt;%
  ggplot(aes(x = confirmed/1000, y = week)) +
  geom_bar(stat = &amp;quot;identity&amp;quot;, position = &amp;quot;dodge&amp;quot;, fill = &amp;quot;blue4&amp;quot;) + 
  facet_wrap(~ country_region) +
  labs(y = &amp;quot;&amp;quot;, x = &amp;quot;Confirmed Cases (in thousands)&amp;quot;) + 
  scale_x_continuous(labels = comma) +
  theme_bw() +
  theme(legend.position = &amp;quot;none&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/Coronavirus_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;960&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;deaths&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Deaths&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;country_dat %&amp;gt;%
  ggplot(aes(x = deaths/1000, y = week)) +
  geom_bar(stat = &amp;quot;identity&amp;quot;, position = &amp;quot;dodge&amp;quot;, fill = &amp;quot;red4&amp;quot;) + 
  facet_wrap(~ country_region) +
  labs(y = &amp;quot;&amp;quot;, x = &amp;quot;Deaths (in thousands)&amp;quot;) + 
  scale_x_continuous(labels = comma) +
  theme_bw() +
  theme(legend.position = &amp;quot;none&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/Coronavirus_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;960&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;recoveries&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Recoveries&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;country_dat %&amp;gt;%
  ggplot(aes(x = recoveries/1000, y = week)) +
  geom_bar(stat = &amp;quot;identity&amp;quot;, position = &amp;quot;dodge&amp;quot;, fill = &amp;quot;green4&amp;quot;) + 
  facet_wrap(~ country_region) +
  labs(y = &amp;quot;&amp;quot;, x = &amp;quot;Recovered (in thousands)&amp;quot;) + 
  scale_x_continuous(labels = comma) +
  theme_bw() +
  theme(legend.position = &amp;quot;none&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/Coronavirus_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;960&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;confirmed-cases-trend&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Confirmed Cases Trend&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sum_dat &amp;lt;- country_dat %&amp;gt;%
  group_by(date, country_region) %&amp;gt;%
  summarize(confirmed = sum(confirmed)) %&amp;gt;%
  ungroup() %&amp;gt;%
  mutate(country_region = if_else(country_region == &amp;quot;Korea, South&amp;quot;, &amp;quot;S. Korea&amp;quot;, country_region))
  
sum_dat %&amp;gt;%  
  ggplot(aes(x = date, y = confirmed, color = country_region)) +
  geom_line(size = .8) +
  geom_text(data = sum_dat %&amp;gt;% filter(date == last(date)), 
            aes(label = country_region, x = date + .1, 
                y = confirmed, color = country_region), 
            hjust = -.01) +
  scale_y_continuous(labels = comma, breaks = seq(0, 800000, 50000)) +
  xlim(ymd(&amp;quot;2020-01-22&amp;quot;), ymd(&amp;quot;2020-04-22&amp;quot;)) + 
  scale_color_brewer(type = &amp;quot;qual&amp;quot;, palette = 2) + 
  labs(x = &amp;quot;&amp;quot;, y = &amp;quot;Confirmed Cases&amp;quot;, color = &amp;quot;Country&amp;quot;) + 
  ggtitle(&amp;quot;Confirmed Cases as of April 17, 2020&amp;quot;) +
  theme_bw() +
  theme(legend.position = &amp;quot;none&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/Coronavirus_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;unemployment-claims-in-the-us&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Unemployment Claims in the US&lt;/h1&gt;
&lt;p&gt;I am retrieving the data from the &lt;code&gt;tidyquant&lt;/code&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;icsa_dat &amp;lt;- &amp;quot;ICSA&amp;quot; %&amp;gt;%
  tq_get(get = &amp;quot;economic.data&amp;quot;,  
         from = &amp;quot;1967-01-07&amp;quot;) %&amp;gt;%
  rename(claims = price)


glimpse(icsa_dat)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 2,780
## Columns: 3
## $ symbol &amp;lt;chr&amp;gt; &amp;quot;ICSA&amp;quot;, &amp;quot;ICSA&amp;quot;, &amp;quot;ICSA&amp;quot;, &amp;quot;ICSA&amp;quot;, &amp;quot;ICSA&amp;quot;, &amp;quot;ICSA&amp;quot;, &amp;quot;ICSA&amp;quot;, &amp;quot;ICSA&amp;quot;…
## $ date   &amp;lt;date&amp;gt; 1967-01-07, 1967-01-14, 1967-01-21, 1967-01-28, 1967-02-04, 1…
## $ claims &amp;lt;int&amp;gt; 208000, 207000, 217000, 204000, 216000, 229000, 229000, 242000…&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;icsa_dat %&amp;gt;%
  ggplot(aes(x = date, y = claims)) + 
  geom_line(color = &amp;quot;blue&amp;quot;) + 
  scale_y_continuous(labels = comma) +
  labs(x = &amp;quot;Date&amp;quot;, y = &amp;quot;Claims&amp;quot;) + 
  ggtitle(&amp;quot;Unemployment Claims: 1967 to 2020&amp;quot;) +
  theme_bw()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/Coronavirus_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;icsa_dat %&amp;gt;%
  mutate(year = year(date)) %&amp;gt;%
  filter(year &amp;gt; 2007) %&amp;gt;%
  ggplot(aes(x = date, y = claims)) + 
  geom_line(color = &amp;quot;blue&amp;quot;) + 
  scale_y_continuous(labels = comma) +
  labs(x = &amp;quot;Date&amp;quot;, y = &amp;quot;Claims&amp;quot;) + 
  ggtitle(&amp;quot;Unemployment Claims: 2008 to 2020&amp;quot;) +
  theme_bw()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/Coronavirus_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;icsa_dat %&amp;gt;%
  mutate(year = year(date)) %&amp;gt;%
  filter(year &amp;gt; 2018) %&amp;gt;%
  ggplot(aes(x = date, y = claims)) + 
  geom_line(color = &amp;quot;blue&amp;quot;) + 
  scale_y_continuous(labels = comma) +
  labs(x = &amp;quot;Date&amp;quot;, y = &amp;quot;Claims&amp;quot;) + 
  ggtitle(&amp;quot;Unemployment Claims: 2019 to 2020&amp;quot;) +
  theme_bw()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/Coronavirus_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;causal-inference-on-impact-of-covid-19-lockdowns-on-unemployment-claims&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Causal Inference on Impact of COVID-19 Lockdowns on Unemployment Claims&lt;/h1&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;
&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;
Sometimes &lt;a href=&#34;https://twitter.com/hashtag/causalinference?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#causalinference&lt;/a&gt; is simple.&lt;br&gt;&lt;br&gt;“What&#39;s the immediate causal effect of the &lt;a href=&#34;https://twitter.com/hashtag/COVID19?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#COVID19&lt;/a&gt; lockdowns on unemployment?”&lt;br&gt;&lt;br&gt;The answer is “Unprecedented”. &lt;br&gt;&lt;br&gt;We know we&#39;re in deep trouble when a time series is all we need. &lt;a href=&#34;https://t.co/cXK0wLw3no&#34;&gt;https://t.co/cXK0wLw3no&lt;/a&gt; &lt;a href=&#34;https://t.co/kS4PvVwihM&#34;&gt;pic.twitter.com/kS4PvVwihM&lt;/a&gt;
&lt;/p&gt;
— Miguel Hernán (&lt;span class=&#34;citation&#34;&gt;@_MiguelHernan&lt;/span&gt;) &lt;a href=&#34;https://twitter.com/_MiguelHernan/status/1244215937978576898?ref_src=twsrc%5Etfw&#34;&gt;March 29, 2020&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;p&gt;Below, I use the &lt;code&gt;CausalImpact&lt;/code&gt; package to run a Bayesian structural time-series analysis. For more information on the package, please see this &lt;a href=&#34;https://cran.r-project.org/web/packages/CausalImpact/vignettes/CausalImpact.html&#34;&gt;vignette&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dates &amp;lt;- icsa_dat %&amp;gt;% 
  pull(date)

pre_period &amp;lt;- c(dates[1], dates[2776])
post_period &amp;lt;- c(dates[2777], dates[2780])

dat &amp;lt;- icsa_dat %&amp;gt;%
  select(date, y = claims)

impact &amp;lt;- CausalImpact(dat, pre_period, post_period)

# summary(impact, &amp;quot;report&amp;quot;)  # this creates the following report :)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;analysis-report-causalimpact&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Analysis report: CausalImpact&lt;/h2&gt;
&lt;p&gt;Below is the report generated by &lt;code&gt;CausalImpact&lt;/code&gt; with some edits by me.&lt;/p&gt;
&lt;p&gt;During the post-COVID lockdown period, the average number of unemployment claims filed was approximately 5.51M. By contrast, in the absence of the lockdown, we would have expected an average number of claims of 0.25M. The 95% interval of this counterfactual prediction is [0.22M, 0.29M]. Subtracting this prediction from the observed response yields an estimate of the causal effect the intervention had on the response variable. This effect is 5.25M with a 95% interval of [5.22M, 5.29M].&lt;/p&gt;
&lt;p&gt;Summing up the individual data points during the post-lockdown period, the total number of unemployment claims filed equaled 22.03M. By contrast, had the intervention not taken place, we would have expected a sum of 1.01M. The 95% interval of this prediction is [0.88M, 1.15M].&lt;/p&gt;
&lt;p&gt;The above results are given in terms of absolute numbers. In relative terms, the number of unemployment claims showed an increase of +2073%. The 95% interval of this percentage is [+2059%, +2086%].&lt;/p&gt;
&lt;p&gt;The probability of obtaining this effect by chance is very small (Bayesian one-sided tail-area probability p = 0.001). This means the causal effect can be considered statistically significant.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Nepal Earthquake</title>
      <link>/post/nepal_earthquake/</link>
      <pubDate>Wed, 20 Nov 2019 00:00:00 +0000</pubDate>
      <guid>/post/nepal_earthquake/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/htmlwidgets/htmlwidgets.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/pymjs/pym.v1.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/widgetframe-binding/widgetframe.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;I wanted to analyze the data from the &lt;a href=&#34;https://en.wikipedia.org/wiki/April_2015_Nepal_earthquake&#34;&gt;April 2015 Nepal earthquake&lt;/a&gt; that resulted in around 10,000 deaths. I am using a &lt;a href=&#34;https://data.world/opennepal/1b7b5d6e-3c98-49f4-a884-a167c4040d3a&#34;&gt;dataset&lt;/a&gt; that I found in &lt;code&gt;data.world&lt;/code&gt;. The data contains date, time, location and magnitude of the earthquake and the many aftershocks that followed. The data is updated as of June 2, 2015.&lt;/p&gt;
&lt;p&gt;Nepal is my birthplace, my homeland. The earthquake was an extremely traumatic event for people who live there. Many people lost family members, their houses. I visited Nepal in 2017 and saw that every other house in Patan, Nepal (close to Kathmandu) was damaged. My relatives would talk about their experience of the earthquakes every day.&lt;/p&gt;
&lt;div id=&#34;libraries&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Libraries&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(geojsonio)
library(broom)
library(gganimate)
library(leaflet)
library(widgetframe)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;read-in-the-data-and-clean&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Read in the data and clean&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;earthquake_dat &amp;lt;- read_csv(&amp;quot;https://raw.githubusercontent.com/meghapsimatrix/Data_Visualization/master/data/earthquake-0-csv-1.csv&amp;quot;) %&amp;gt;%
  mutate(lab = paste0(Epicentre, &amp;quot;; &amp;quot;, Date,&amp;quot;; Magnitude(ML): &amp;quot;, `Magnitude(ML)`))

head(earthquake_dat)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 7
##   Date       `Local Time` Latitude Longitude `Magnitude(ML)` Epicentre  lab     
##   &amp;lt;date&amp;gt;     &amp;lt;time&amp;gt;          &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;           &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;      &amp;lt;chr&amp;gt;   
## 1 2015-06-01 04:35            28.0      85.5             4   Sindhupal… Sindhup…
## 2 2015-05-31 13:54            28.3      84.5             4.2 Lamjung    Lamjung…
## 3 2015-05-30 22:13            27.8      85.2             4.5 Nuwakot    Nuwakot…
## 4 2015-05-30 20:35            28.0      85.2             4   Rasuwa/Nu… Rasuwa/…
## 5 2015-05-30 01:52            27.8      85.2             4   Dhading /… Dhading…
## 6 2015-05-29 15:44            28        85.0             5.2 Dhading    Dhading…&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# there is one entry where I think the lat and long are switched
summary(earthquake_dat$Latitude)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   26.94   27.71   27.82   28.06   27.98   84.71&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(earthquake_dat$Longitude)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   28.16   85.23   85.80   85.25   86.06   86.67&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Gorkha seems like the lat and long are switched
(outlier &amp;lt;- earthquake_dat %&amp;gt;%
  filter(Latitude == max(Latitude)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 7
##   Date       `Local Time` Latitude Longitude `Magnitude(ML)` Epicentre lab      
##   &amp;lt;date&amp;gt;     &amp;lt;time&amp;gt;          &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;           &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;    
## 1 2015-04-25 18:29            84.7      28.2             5.5 Gorkha    Gorkha; …&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;earthquake_dat &amp;lt;- earthquake_dat %&amp;gt;%
  mutate(Latitude = if_else(lab == outlier$lab &amp;amp; Date == outlier$Date, outlier$Longitude, Latitude),
         Longitude = if_else(lab == outlier$lab &amp;amp; Date == outlier$Date, outlier$Latitude, Longitude))

# Sindhupalchowk seems like the Longitude is wrong
earthquake_dat %&amp;gt;%
  filter(Longitude == min(Longitude))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 7
##   Date       `Local Time` Latitude Longitude `Magnitude(ML)` Epicentre  lab     
##   &amp;lt;date&amp;gt;     &amp;lt;time&amp;gt;          &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;           &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;      &amp;lt;chr&amp;gt;   
## 1 2015-05-08 08:19            27.8      28.9             4.2 Sindhupal… Sindhup…&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sindhupalchowk &amp;lt;- earthquake_dat %&amp;gt;%
  filter(str_detect(Epicentre, &amp;quot;Sindhu&amp;quot;))

# Mean imputing based on other values for Sindhupalchowk
earthquake_dat &amp;lt;- earthquake_dat %&amp;gt;%
  mutate(Longitude = if_else(Longitude == min(Longitude), mean(sindhupalchowk$Longitude), Longitude))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;make-a-map-of-nepal&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Make a Map of Nepal&lt;/h1&gt;
&lt;p&gt;I got the code for the base map from &lt;a href=&#34;https://stackoverflow.com/questions/50859765/chloropleth-map-with-geojson-and-ggplot2&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;np &amp;lt;- geojson_read(&amp;quot;https://raw.githubusercontent.com/mesaugat/geoJSON-Nepal/master/nepal-districts.geojson&amp;quot;,  what = &amp;quot;sp&amp;quot;)
np_dat &amp;lt;- tidy(np)


# plot
np_plot &amp;lt;- ggplot() +
  geom_polygon(data = np_dat, aes( x = long, y = lat, group = group)) 

np_plot&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/Nepal_Earthquake_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;mapping-on-the-earthquake-and-aftershocks&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Mapping on the Earthquake and Aftershocks&lt;/h1&gt;
&lt;p&gt;Now plotting the latitude and longitudes. Size indicates the magnitude of the earthquake.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(np_earthquake &amp;lt;- np_plot + 
  geom_point(data = earthquake_dat, 
             aes(x = Longitude, y = Latitude, 
                 size = `Magnitude(ML)`), 
             color = &amp;quot;red&amp;quot;, alpha = .5) + 
  labs(color = &amp;quot;&amp;quot;) + 
  theme_void() +
  theme(legend.position = &amp;quot;none&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/Nepal_Earthquake_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;animating&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Animating&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;np_animate &amp;lt;- np_earthquake +
  transition_states(Date) +
  labs(title = &amp;#39;Date: {closest_state}&amp;#39;) +
  enter_appear() +
  exit_disappear()

animate(np_animate)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/Nepal_Earthquake_files/figure-html/unnamed-chunk-5-1.gif&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;leaflet&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Leaflet&lt;/h1&gt;
&lt;p&gt;Created using the &lt;code&gt;leaflet&lt;/code&gt; package. Click on the dots on the map to learn the location, date, and the magnitude of the earthquake or aftershock.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;np_leaf &amp;lt;- leaflet(earthquake_dat) %&amp;gt;% 
  setView(lat = 27, lng = 85, zoom = 7) %&amp;gt;%
  addProviderTiles(providers$CartoDB.DarkMatter) %&amp;gt;%
  addCircleMarkers(~Longitude, ~Latitude,
                   radius = ~`Magnitude(ML)`, fillOpacity = 0.5,
                   popup = ~lab, stroke = FALSE)

frameWidget(np_leaf)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;htmlwidget-1&#34; style=&#34;width:100%;height:480px;&#34; class=&#34;widgetframe html-widget&#34;&gt;&lt;/div&gt;
&lt;script type=&#34;application/json&#34; data-for=&#34;htmlwidget-1&#34;&gt;{&#34;x&#34;:{&#34;url&#34;:&#34;/post/Nepal_Earthquake_files/figure-html//widgets/widget_unnamed-chunk-6.html&#34;,&#34;options&#34;:{&#34;xdomain&#34;:&#34;*&#34;,&#34;allowfullscreen&#34;:false,&#34;lazyload&#34;:false}},&#34;evals&#34;:[],&#34;jsHooks&#34;:[]}&lt;/script&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Tidy Tuesday Horror</title>
      <link>/post/tidy_tues_horror/</link>
      <pubDate>Mon, 21 Oct 2019 00:00:00 +0000</pubDate>
      <guid>/post/tidy_tues_horror/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;load-the-data-and-check-duplicates&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Load the Data and Check Duplicates&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(lubridate)
library(kableExtra)
library(ggridges)


# there were complete duplicated rows
dat &amp;lt;- read_csv(&amp;quot;https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-22/horror_movies.csv&amp;quot;) %&amp;gt;%
  distinct(.) # removes complete dups

# check duplicates
dup_title &amp;lt;- dat %&amp;gt;%
  filter(duplicated(title) | duplicated(title, fromLast = TRUE)) %&amp;gt;%
  arrange(title)

# examined they seem different movies even though same title
dup_title %&amp;gt;%
  filter(duplicated(plot))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 0 x 12
## # … with 12 variables: title &amp;lt;chr&amp;gt;, genres &amp;lt;chr&amp;gt;, release_date &amp;lt;chr&amp;gt;,
## #   release_country &amp;lt;chr&amp;gt;, movie_rating &amp;lt;chr&amp;gt;, review_rating &amp;lt;dbl&amp;gt;,
## #   movie_run_time &amp;lt;chr&amp;gt;, plot &amp;lt;chr&amp;gt;, cast &amp;lt;chr&amp;gt;, language &amp;lt;chr&amp;gt;,
## #   filming_locations &amp;lt;chr&amp;gt;, budget &amp;lt;chr&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dup_title %&amp;gt;%
  filter(duplicated(release_date)| duplicated(release_date, fromLast = TRUE))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2 x 12
##   title genres release_date release_country movie_rating review_rating
##   &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;  &amp;lt;chr&amp;gt;        &amp;lt;chr&amp;gt;           &amp;lt;chr&amp;gt;                &amp;lt;dbl&amp;gt;
## 1 The … Comed… 21-Jul-15    USA             &amp;lt;NA&amp;gt;                   5.2
## 2 The … Comed… 21-Jul-15    USA             NOT RATED              3.6
## # … with 6 more variables: movie_run_time &amp;lt;chr&amp;gt;, plot &amp;lt;chr&amp;gt;, cast &amp;lt;chr&amp;gt;,
## #   language &amp;lt;chr&amp;gt;, filming_locations &amp;lt;chr&amp;gt;, budget &amp;lt;chr&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# The Jokesters seems to be a duplicate but with different rating and run time
# Deleting it for now
dat &amp;lt;- dat %&amp;gt;%
  filter(title != &amp;quot;The Jokesters (2015)&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;genres&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Genres&lt;/h1&gt;
&lt;p&gt;The genre column looked extremely messy so some data munging fun. Each film can be categorized into multiple genres.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dat_long &amp;lt;- dat %&amp;gt;% 
  separate_rows(genres, sep = &amp;quot;\\|&amp;quot;) %&amp;gt;% # long format
  mutate(genres = str_trim(genres))  

# Just to check - looks okay - just 1 movie with no genre
table(dat_long$genres, useNA = &amp;quot;ifany&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##     Action      Adult  Adventure  Animation  Biography     Comedy 
##        335          1        115         39          4        511 
##      Crime      Drama     Family    Fantasy    History     Horror 
##        120        529         11        229          6       3309 
##      Music    Musical    Mystery Reality-TV    Romance     Sci-Fi 
##          5         13        453          1         99        308 
##      Sport   Thriller        War    Western       &amp;lt;NA&amp;gt; 
##          4       1369         14         15          1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dat_long &amp;lt;- dat_long %&amp;gt;%
  mutate(genres = fct_infreq(fct_lump(genres, n = 8))) # Factor keeping 8 most frequent categories and lumping the rest to Other and order the factor by frequency&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;table-number-of-films-per-genre&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Table: Number of Films per Genre&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;genre_count &amp;lt;- dat_long %&amp;gt;%
  filter(!is.na(genres)) %&amp;gt;%
  group_by(genres) %&amp;gt;%
  summarize(n = n()) %&amp;gt;%
  ungroup() 

kable(genre_count, format = &amp;quot;html&amp;quot;, table.attr = &amp;quot;style = \&amp;quot;color: white;\&amp;quot;&amp;quot;) %&amp;gt;%
  kable_styling(bootstrap_options = &amp;quot;striped&amp;quot;, full_width = F)&lt;/code&gt;&lt;/pre&gt;
&lt;table style=&#34;color: white; width: auto !important; margin-left: auto; margin-right: auto;&#34; class=&#34;table table-striped&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
genres
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
n
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Horror
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3309
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Thriller
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1369
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Drama
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
529
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Comedy
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
511
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mystery
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
453
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Other
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
447
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Action
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
335
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Sci-Fi
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
308
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Fantasy
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
229
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;bar-graph-distribution-of-genres&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Bar Graph: Distribution of Genres&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;genre_count %&amp;gt;%
  ggplot(aes(x = genres, y = n, fill = genres)) +
  geom_bar(stat = &amp;quot;identity&amp;quot;) + 
  scale_y_continuous(labels = scales::comma) +  # y axis to have commas 
  scale_fill_brewer(palette =&amp;quot;BuPu&amp;quot;, direction = -1) + # reverse order the palette
  theme_light() + 
  labs(x = &amp;quot;&amp;quot;, y = &amp;quot;Number of Films&amp;quot;) + 
  theme(legend.position = &amp;quot;none&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/tidy_tues_horror_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;review-rating-by-release-year&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Review Rating by Release Year&lt;/h1&gt;
&lt;p&gt;Some of the years are &lt;code&gt;dmy&lt;/code&gt; format, some just have the years. I am extracting the year and filling in any that didn’t parse with the year value from the original release_date column. No missing values for year :)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;date_dat &amp;lt;- dat %&amp;gt;%
  mutate(date = dmy(release_date),
         yr = year(date),
         yr = ifelse(is.na(yr), release_date, yr))

table(is.na(date_dat$yr))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## FALSE 
##  3310&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;table(is.na(date_dat$review_rating))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## FALSE  TRUE 
##  3058   252&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;date_dat %&amp;gt;%
  select(release_date, date, yr) %&amp;gt;%
  filter(is.na(date)) %&amp;gt;%
  head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 3
##   release_date date       yr   
##   &amp;lt;chr&amp;gt;        &amp;lt;date&amp;gt;     &amp;lt;chr&amp;gt;
## 1 2017         NA         2017 
## 2 2013         NA         2013 
## 3 2012         NA         2012 
## 4 2013         NA         2013 
## 5 2017         NA         2017 
## 6 2017         NA         2017&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;date_dat %&amp;gt;%  
  ggplot(aes(x = yr, y = review_rating, fill = yr)) +
  geom_boxplot(alpha = .5) + 
  labs(x = &amp;quot;Release Year&amp;quot;, y = &amp;quot;Review Rating&amp;quot;) + 
  theme_light()  + 
  theme(legend.position = &amp;quot;none&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/tidy_tues_horror_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Looks like there is a slight increase in ratings for newer films.&lt;/p&gt;
&lt;p&gt;And here is a ridgeline plot :)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;date_dat %&amp;gt;%  
  ggplot(aes(y = yr, x = review_rating, fill = yr)) +
  geom_density_ridges(alpha = .5) + 
  labs(y = &amp;quot;Release Year&amp;quot;, x = &amp;quot;Review Rating&amp;quot;) +
  theme_light() + 
  theme(legend.position = &amp;quot;none&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/tidy_tues_horror_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
