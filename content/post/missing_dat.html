---
title: "Missing Data in Propensity Score Analysis"
author: "Megha Joshi"
date: 2020-04-16
categories: ["R"]
tags: ["propensity score", "missing data", "causal inference"]
bibliography: references.bib
csl: apa.csl
---



<p>Theories behind propensity score analysis assume that the covariates are fully observed <span class="citation">(Rosenbaum &amp; Rubin, 1983, 1984)</span>. However, in practice, observational analyses require large administrative databases or surveys, which inevitably will have missingness in the covariates. The response patterns of people with missing covariates may be different than those of people with observed data <span class="citation">(Mohan, Pearl, &amp; Tian, 2013)</span>. Therefore, ways to handle missing covariate data need to be examined. The basic estimation of propensity scores using logistic regression will delete cases with missing data, which can be problematic as it can cause bias in the treatment effect estimates <span class="citation">(Baraldi &amp; Enders, 2010)</span>.</p>
<div id="missing-data-methods-in-propensity-score-analysis" class="section level2">
<h2>Missing Data Methods in Propensity Score Analysis</h2>
<p>Below I explain three major methods used in the applied propensity score analysis literature when <span class="math inline">\(X\)</span> is not fully observed. I also explain three other methods to handle missing data that are not commonly used in applied literature but have been proposed theoretically. I also describe the assumptions about missing data and strong ignorability underlying each of the methods. Let <span class="math inline">\(X_{obs}\)</span> indicate the observed parts of <span class="math inline">\(X\)</span> and <span class="math inline">\(X_{mis}\)</span> indicate the missing parts of <span class="math inline">\(X\)</span>. <span class="math inline">\(D\)</span> indicates the fully observed treatment indicator and <span class="math inline">\(Y\)</span> indicates a fully observed outcome variable.</p>
<div id="complete-case-analysis" class="section level3">
<h3>Complete Case Analysis</h3>
<p>This approach deletes cases with missing data in any of the variables used in the analysis <span class="citation">(Baraldi &amp; Enders, 2010; Hill, 2004)</span>. The traditional propensity score estimation method of using logistic regression implements complete case analysis by default. Therefore, this method is commonly used in applied research. The data that remains after deleting cases with missing data are assumed to be a simple random sample of the full data <span class="citation">(Baraldi &amp; Enders, 2010)</span>. Missingness is not related to any study variables nor to the hypothetically complete values of itself (Equations  and ). According to <span class="citation">Hill (2004)</span>, the assumption underlying complete case analysis is that the joint distributions of <span class="math inline">\(X_{obs}\)</span> and <span class="math inline">\(X_{mis}\)</span> are same across the two treatment conditions:
<span class="math display">\[\begin{equation}
X_{obs}, X_{mis} \perp\!\!\!\perp D
\end{equation}\]</span>
Therefore, an unbiased causal effect estimate can be retrieved after deleting cases with missing data. Such an assumption is very stringent and unlikely to be met in the types of data required for propensity score analyses <span class="citation">(Baraldi &amp; Enders, 2010; Hill, 2004)</span>. As mentioned above, deleting cases can also result in loss of power. Additionally, whether <span class="math inline">\(X_{mis}\)</span> is balanced between the treatment groups cannot be confirmed.</p>
</div>
<div id="multiple-imputation" class="section level3">
<h3>Multiple Imputation</h3>
<p>Multiple imputation (MI) generates multiple sets of data with the missing values drawn from an imputation model <span class="citation">(Mitra &amp; Reiter, 2016; Rubin, 1987)</span>. MI will create <span class="math inline">\(m &gt; 1\)</span> imputed datasets that contain different imputed values <span class="citation">(Murray, 2018; van Buuren, 2018)</span>. Analyses can be performed on each of the datasets and results from each dataset can be aggregated across to derive a final estimate, standard error, degrees of freedom, and test result. Thus, MI involves two stages: (1) imputation and creation of the <span class="math inline">\(m\)</span> imputed datasets, and (2) analysis and pooling of estimates across the datasets <span class="citation">(Murray, 2018; van Buuren, 2018)</span>.</p>
<p>There are two approaches for imputing multivariate missing data: (1) joint modeling, JM, and (2) fully conditional specification, FCS, also called multivariate imputation by chained equations, MICE <span class="citation">(Murray, 2018; van Buuren, 2018; van Buuren &amp; Groothuis-Oudshoorn, 2011)</span>. JM entails jointly modeling variables with missingness by drawing from a multivariate distribution <span class="citation">(Murray, 2018; van Buuren, 2018; van Buuren &amp; Groothuis-Oudshoorn, 2011)</span>. FCS entails univariate conditional imputation models of variables with missing data that iteratively condition on all other variables using Monte Carlo Markov chain methods <span class="citation">(van Buuren, 2018; van Buuren &amp; Groothuis-Oudshoorn, 2011)</span>. JM imputes all variables simultaneously whereas FCS imputes one variable at a time <span class="citation">(van Buuren, 2018)</span>. Because JM requires specification of a joint distribution for all the variables, it may not be as flexible as FCS when dealing with a large number of covariates with missing data <span class="citation">(Akande, Li, &amp; Reiter, 2017)</span>. However, FCS is computationally more intensive than JM <span class="citation">(van Buuren, 2018)</span>. FCS also has been shown to outperform JM for categorical variables and is more robust under mis-specification of imputation model <span class="citation">(van Buuren, 2018)</span>. Therefore, <span class="citation">van Buuren (2018)</span> recommended to use FCS over JM.</p>
<p>If the missingness mechanism is MAR or MCAR and if assumptions underlying the imputation model are correct, MI will yield unbiased results, as it uses the information available in <span class="math inline">\(X_{obs}\)</span> to impute missing values <span class="citation">(Murray, 2018)</span>. In the causal inference context, <span class="citation">Hill (2004)</span> argued that MI relies on the assumption of <em>latent ignorability</em>, a concept introduced by <span class="citation">Frangakis &amp; Rubin (1999)</span>. The assumption requires that the treatment assignment mechanism is ignorable given complete covariate data including the values that are latent or missing. These missing values are derived from MI. Below, let <span class="math inline">\(e_{MI}(X)\)</span> denote propensity scores derived after multiple imputation:
<span class="math display">\[\begin{equation}
X_{obs}, X_{mis} \perp\!\!\!\perp D| e_{MI}(X)
\end{equation}\]</span>
<span class="math display">\[\begin{equation}
Y(1), Y(0) \perp\!\!\!\perp D | e_{MI}(X)
\end{equation}\]</span>
<span class="citation">Hill (2004)</span> proposed two different ways to combine propensity scores estimated in each of the <em>m</em> datasets:</p>
<div id="multiple-imputation-across-mi-across" class="section level5">
<h5>Multiple Imputation Across (MI Across)</h5>
<p>This approach involves creating <em>m</em> imputed datasets and then estimating propensity scores within each of the datasets and then averaging each unit’s <em>m</em> propensity scores across the <em>m</em> datasets <span class="citation">(Hill, 2004)</span>. Stratification, matching or IPW can be implemented using these averaged propensity scores <span class="citation">(Hill, 2004)</span>. Outcome models that include covariates will need to use the weights or strata derived from the averaged propensity scores and the <em>m</em> sets of covariate values. The weighted regression estimates will then need to be pooled.</p>
</div>
<div id="multiple-imputation-within-mi-within" class="section level5">
<h5>Multiple Imputation Within (MI Within)</h5>
<p>This approach involves creating <em>m</em> imputed datasets and then estimating propensity scores within each of the datasets <span class="citation">(Hill, 2004)</span>. Instead of averaging the propensity scores across the datasets, this method entails conditioning on the propensity scores within the datasets and running the outcome analyses within each dataset <span class="citation">(Hill, 2004)</span>. The separate regression estimates have to be pooled.</p>
</div>
</div>
<div id="generalized-propensity-scores" class="section level3">
<h3>Generalized Propensity Scores</h3>
<p><span class="citation">Rosenbaum &amp; Rubin (1984)</span> proposed the use of generalized propensity scores (GPS) as a way to address missing covariate data. The GPS represents the probability of treatment given observed covariates and missingness indicators <span class="citation">(Rosenbaum &amp; Rubin, 1984)</span>:
<span class="math display">\[\begin{equation}
e^*(X) = P(D = 1|X_{obs}, R)
\end{equation}\]</span>
Conditioning on <span class="math inline">\(e^*(X)\)</span> will balance the treatment groups in terms of the observed covariates and missingness patterns <span class="citation">(Rosenbaum &amp; Rubin, 1984)</span>. The observed part of <span class="math inline">\(X\)</span> and the missingness pattern indicators, <span class="math inline">\(R\)</span>, will be independent of treatment assignment given the GPS <span class="citation">(Rosenbaum &amp; Rubin, 1984)</span>:
<span class="math display">\[\begin{equation}
X_{obs}, R \perp\!\!\!\perp D| e^*(X)
\end{equation}\]</span>
However, conditioning on GPS will not balance the groups in terms of the unobserved values of <span class="math inline">\(X\)</span> <span class="citation">(Rosenbaum &amp; Rubin, 1984)</span>:
<span class="math display">\[\begin{equation}
X_{mis} \not\!\perp\!\!\!\perp D| e^*(X)
\end{equation}\]</span>
Although this technique of treating missing data is not generally recommended for other types of missing data analyses, it has been recommended for use in propensity score analysis literature <span class="citation">(Rosenbaum &amp; Rubin, 1984; Stuart, 2010)</span>. In the context of propensity score analysis, this approach does not assume latent ignorability of treatment assignment because legitimate values for missing data are never derived. The assumption underlying this method is that balancing the treatment and control groups on <span class="math inline">\(X_{obs}\)</span> and <span class="math inline">\(R\)</span> is a sufficient condition to satisfy ignorability. With the GPS, the treatment and control groups are possibly not going to be balanced in terms of <span class="math inline">\(X_{mis}\)</span>.</p>
<p>For large studies with few missing data patterns, <span class="citation">Rosenbaum &amp; Rubin (1984)</span> suggested estimating separate logit models for each missingness pattern. In practice, it is common to encounter many patterns of missing data. For these scenarios, <span class="citation">Rosenbaum &amp; Rubin (1984)</span> suggested creating an additional category indicating missingness for categorical variables. For continuous variables, <span class="citation">Stuart (2010)</span> recommended imputing missing data with a single arbitrary value, such as the overall mean of the covariate, and then creating a missingness indicator variable. In general missing data analysis context, <span class="citation">van Buuren (2018)</span> noted that this method of combining arbitrary (mean) imputation along with missingness indicators can underestimate the standard error of the estimate of interest.</p>
<p>The CART algorithms treat missing data natively as they split missingness as a category itself. In this manner, this approach is similar to the GPS which uses missingness pattern indicators when estimating propensity scores. The missingness categories are used to estimate propensity scores and conditioning on the propensity scores should balance the treatment and control condition in terms of the patterns. However, splitting does not actually impute the missing data so it is plausible to assume that like GPS, scores derived using the splitting method will not balance the groups in terms of the latent missing data. In addition, unlike MI, there are no imputed complete datasets saved to analyze for the outcome model. Therefore, splitting would need to be combined with some other technique for outcome modeling.</p>
</div>
<div id="other-methods" class="section level3">
<h3>Other Methods</h3>
<p>The following methods have been discussed theoretically in literature examining missing data methods in propensity score analysis. However, these methods are not commonly used in applied literature.</p>
<div id="complete-variables" class="section level4">
<h4>Complete Variables</h4>
<p>This method removes any variable with missing data <span class="citation">(Hill, 2004)</span>. By removing variables with missing data, the approach assumes that the distribution of those variables (both the observed and missing parts) are the same across the two treatment groups <span class="citation">(Hill, 2004)</span>. If this assumption does not hold, then this method can result in bias in treatment effect estimates due to removal of important confounding variables <span class="citation">(Hill, 2004)</span>.</p>
</div>
<div id="dagostino-and-rubin-expectation-maximization" class="section level4">
<h4>D’Agostino and Rubin Expectation Maximization</h4>
<p>Another approach is a method introduced by <span class="citation">D’Agostino &amp; Rubin (2000)</span>, which estimates propensity scores using an Expectation Conditional Maximization (ECM) algorithm <span class="citation">(Hill, 2004)</span>. This method, DR, works similar to GPS as it models <span class="math inline">\(X_{obs}\)</span>, <span class="math inline">\(R\)</span>, and the treatment indicator variable. However, instead of imputing <span class="math inline">\(X_{mis}\)</span>, the DR method uses ECM to estimate propensity scores in presence of missing data <span class="citation">(Hill, 2004)</span>. The assumption underlying DR is that within each missingness pattern defined by <span class="math inline">\(R\)</span>, <span class="math inline">\(X_{mis}\)</span> is independent of <span class="math inline">\(D\)</span> given the observed data, <span class="math inline">\(X_{obs}\)</span> <span class="citation">(Hill, 2004)</span>:
<span class="math display">\[\begin{equation}
X_{mis} \perp\!\!\!\perp D| X_{obs}, R
\end{equation}\]</span>
Such independence is sufficient to satisfy the ignorability assumption in presence of missing covariate data. With this method, the assumption cannot be checked, however, as DR does not actually impute the missing values. This method is not readily available in commonly used software like R.</p>
</div>
<div id="multiple-imputation-missingness-indicator-pattern-mixutre" class="section level4">
<h4>Multiple Imputation Missingness Indicator Pattern Mixutre</h4>
<p><span class="citation">Qu &amp; Lipkovich (2009)</span> extended MI by introducing the missingness indicator pattern mixture (MIMP) approach, which is the same as MI but adds <span class="math inline">\(R\)</span> in the propensity score estimation model. The rationale behind this approach is to use information given by missingness patterns to estimate treatment propensities. The method will assume latent ignorabilty. However, this approach should also balance the treatment group on <span class="math inline">\(R\)</span> as <span class="math inline">\(R\)</span> is used to estimate the propensity scores:
<span class="math display">\[\begin{equation}
X_{obs}, X_{mis}, R \perp\!\!\!\perp D| e_{MIMP}(X)
\end{equation}\]</span>
<span class="citation">Qu &amp; Lipkovich (2009)</span> argued that extending MI by adding R to the propensity score estimation accounts for non-ignorability or MNAR <span class="citation">(Qu &amp; Lipkovich, 2009; van Buuren, 2018)</span>. This method allows missingness itself to provide information on missingness:
<span class="math display">\[\begin{equation}
P(X| X_{obs}, R = 1) \neq P(X| X_{obs}, R = 0)
\end{equation}\]</span></p>
</div>
</div>
</div>
<div id="performance-of-missing-data-methods-in-propensity-score-analysis" class="section level1">
<h1>Performance of Missing Data Methods in Propensity Score Analysis</h1>
<p>Few methodological studies have examined the performance of missing data methods when using propensity score analysis for causal inference. <span class="citation">Hill (2004)</span>, an unpublished working paper, compared complete case analysis, complete variables analysis, DR, and the two MI methods including and excluding the outcome when imputing data. The generated data included eight covariates, three categorical, drawn from multinominal distribution, and five continuous, drawn from multivariate normal distribution. Ignorable (MAR) missingness was simulated based on <span class="math inline">\(X_{obs}\)</span>. Missingness rates ranged from 13% to 37%. A binary treatment variable was simulated as a linear function of the covariates, with an average of 23% of each sample in the treatment condition. Potential outcomes were generated with non-parallel response surface throughout the covariate space (treatment effect heterogeneity was present) and the outcomes were predicted by four of the covariates. <span class="citation">Hill (2004)</span> used the matching method and calculated the difference in means of the outcomes between the treated and the untreated groups to estimate the ATT. The sample size per simulation iteration was 1000 and the number of imputations used for MI methods was 10.</p>
<p><span class="citation">Hill (2004)</span> calculated percent reduction in bias defined as the reduction in the absolute difference in means of the covariates between the treatment groups before matching compared to after matching divided by the absolute initial difference in means. Results from <span class="citation">Hill (2004)</span> showed that complete case analysis increased covariate imbalance between the treatment groups. Complete variables approach resulted in even worse imbalance, especially for the variables with missing data. MI techniques performed better than DR with MI Across including the outcome showing the best percent reduction in bias for balance diagnostics. In terms of absolute bias for the treatment effect estimate, MI Across without the outcome performed best. In terms of mean squared error, MI Across with the outcome performed best. The MI techniques were recommended over DR, complete case, and complete variable analysis.</p>
<p><span class="citation">Mitra &amp; Reiter (2016)</span> conducted a similar study comparing the two different methods of multiple imputation. The outcome variable was not considered during imputation (to adhere to the spirit of propensity scores as being blind to the outcome). The generated data included two covariates one of which contained missing data generated following MAR mechanism. The sample size for each simulated data set contained approximately 100 treated units and 1000 untreated units. Treatment indicators were generated as a linear function of the complete variable only, of the variable with missing data, and of both of the variables. The number of simulation iterations conducted was 1000. One-to-one matching method was used to condition on the propensity scores and the ATT was estimated by taking the simple difference in the means of the outcome variables between the treated and the matched untreated group. MI Across showed greater bias reduction than MI Within, especially in conditions where the variable with missingness predicted treatment assignment.</p>
<p><span class="citation">Qu &amp; Lipkovich (2009)</span> compared the MIMP approach that they introduced to complete case analysis, the MI method, and a pattern mixture (MP) method that is similar to the GPS except the authors combined patterns that contained few cases. Twelve covariates were generated from a compound symmetric multivariate normal distribution. The treatment assignment indicator was generated as a linear function of the covariates. The outcome was generated as a linear function of the covariates and the treatment indicator variable. Ignorable (MCAR and MAR) and non-ignorable (MNAR) missingness were simulated based on linear combinations of the covariates. The number of simulation iterations conducted was 5000 and the number of imputations generated for MI was 5. The results showed that the complete case analysis removed bias under all three missingness conditions. I note that this result is counter-intuitive as theoretically, complete case analysis should introduce bias especially under MNAR. Under MAR, all the methods showed low bias. Under MNAR, MP and MIMP showed lower bias than MI.</p>
<p><span class="citation">Leyrat et al. (2019)</span> compared complete case analysis, GPS, the two MI methods, and an MI approach that averages the covariate values across the imputed datasets and then estimates the propensity scores. For MI, they experimented including the outcome and not including the outcome in the imputation model, similar to <span class="citation">Hill (2004)</span>. The authors generated three covariates from a multivariate normal distribution, with one dichotomized. Treatment assignment was generated as a linear function of all three covariates. A binary outcome was generated as a linear function of the covariates and the treatment assignment indicator. The authors calculated log relative risk, log odds ratio and risk difference using IPW to condition on the propensity scores. MAR missingness was generated in the first and the third (binary) covariate as a function of the fully observed second covariate, treatment indicator and the outcome. The authors experimented with making missingness dependent and independent of the outcome. The authors did not include any covariates in the outcome model. For each condition, 5000 datasets with a sample size of 2000 (30% in the treatment group) each were generated. The results indicated that complete case analysis and GPS resulted in strong absolute bias in the treatment effect estimates. MI methods showed lower bias. Including the outcome in imputation model resulted in lower absolute bias even in cases where the outcome did not predict missingness. MI Across with the outcome included showed the lowest absolute bias (near zero). All of the MI methods showed adequate coverage rates whereas the complete case and GPS methods showed very large bias so their coverage rates were also inadequate. The authors recommended MI Across with the outcome included in the imputation model.</p>
<p><span class="citation">Crowe, Lipkovich, &amp; Wang (2010)</span> conducted a simulation study comparing complete case analysis, treatment mean imputation (imputing missing values with the mean of the variable in the treatment group), and three types of MI Within. The three types entailed: (1) including only the covariates in the imputation model; (2) including the covariates and the treatment indicator in the imputation model; (3) including the covariates, treatment indicator and the outcome variable in the imputation model. The authors generated data for 2000 subjects with six continuous covariates from a compound symmetric multivariate normal distribution, with correlation between covariates equal to 0.3. The treatment assignment indicator was generated as a linear function of only one of the covariates and a binary outcome was generated as a linear function of that covariate and the treatment assignment indicator. MCAR and MAR missingness were generated that affected three of the covariates including the one that influenced both treatment assignment and outcome. The number of simulation iterations per condition was 3000. Results showed bias in treatment effect estimates even in conditions with no missing data and no confounding. This result is odd as theoretically there should be no bias in these conditions. Complete case analysis and MI that included all covariates, the treatment indicator and the outcome variable produced estimates that were not significantly different from estimates obtained under no missing data condition. Treatment mean imputation produced slightly larger bias under MCAR, and even larger bias under MAR. The other two MI methods (including covariates only, and including covariates and the treatment indicator) resulted in substantial bias.</p>
<p><span class="citation">Leyrat et al. (2019)</span> and <span class="citation">Crowe et al. (2010)</span> examined missing data methods to estimate treatment effects for a binary outcome variable. The effect estimation procedure for a binary outcome is different from that for a continuous outcome, which is the focus of the present study. Therefore, the results from these studies may not generalize to the context of my study. The results from <span class="citation">Hill (2004)</span>, <span class="citation">Mitra &amp; Reiter (2016)</span>, and <span class="citation">Qu &amp; Lipkovich (2009)</span> are more relevant.</p>
<p><span class="citation">Hill (2004)</span> and <span class="citation">Mitra &amp; Reiter (2016)</span> did not compare MI techniques to the other competing missing data technique of using GPS. All of the articles reviewed also generated the treatment indicator variable as a linear additive function of the covariates, estimated propensity scores using logistic regression, and estimated the treatment effect using multiple linear regression or just taking the plain difference in the means of the outcomes of the treated and untreated groups after matching or weighting. As I noted above, in applied settings, it is common to encounter large sets of covariates which may not have a linear additive relationship with the treatment assignment <span class="citation">(Lee, Lessler, &amp; Stuart, 2009)</span>. Using logistic regression to estimate propensity scores requires the functional form of the model to be specified correctly. Mis-specification can result in imbalanced covariates which can then result in biased treatment effect estimates.</p>
<p>In addition to reviewing the methodological studies above, I also conducted an analysis of 66 applied research articles using propensity scores across three journals focused on educational evaluation: Educational Evaluation and Policy Analysis (n = 38), American Educational Research Journal (n = 18), and Journal of Research on Educational Effectiveness (n = 10). I searched for the term “propensity score analysis” in the webpages of each of the journals and reviewed all of the articles that used propensity score analysis. The articles were from 2003 to 2019; I omitted one study published in the 1990s. Of these articles, 15% used complete case analysis, 14% used GPS, 36% used MI Within, 18% did not specify clearly how missing data were handled, and 17% used other techniques (e.g., hot-deck imputation, mean imputation without indicators). Three of the articles ran MI but only used one of the imputed datasets to conduct the analysis. None used MI Across even though <span class="citation">Hill (2004)</span> and <span class="citation">Mitra &amp; Reiter (2016)</span> recommended it. Moreover, only one of these studies used machine learning algorithm, random forest, to estimate propensity scores <span class="citation">(Im, Hughes, Cao, &amp; Kwok, 2016)</span>. The examination of applied educational research using propensity scores and methodological studies on missing data methods for propensity score analysis poses the need to study missing data methods, especially GPS and MI, and how they perform with flexible propensity score estimation, especially in the context of educational research.</p>
<p>Complete variables analysis is not a missing data method and can result in large bias in treatment effect estimates due to deletion of important confounding variables <span class="citation">(Hill, 2004)</span>. DR is not readily available, has not been commonly used in applied literature, and has been shown to perform worse than MI <span class="citation">(Hill, 2004)</span>. MIMP is also not widely used and has been shown to perform no better than GPS <span class="citation">(Qu &amp; Lipkovich, 2009)</span>.</p>
</div>
<div id="references" class="section level1 unnumbered">
<h1>References</h1>
<div id="refs" class="references">
<div id="ref-akande2017empirical">
<p>Akande, O., Li, F., &amp; Reiter, J. (2017). An empirical comparison of multiple imputation methods for categorical data. <em>The American Statistician</em>, <em>71</em>(2), 162–170.</p>
</div>
<div id="ref-baraldi_introduction_2010">
<p>Baraldi, A. N., &amp; Enders, C. K. (2010). An introduction to modern missing data analyses. <em>Journal of School Psychology</em>, <em>48</em>(1), 5–37. <a href="https://doi.org/10.1016/j.jsp.2009.10.001">https://doi.org/10.1016/j.jsp.2009.10.001</a></p>
</div>
<div id="ref-crowe_comparison_2010">
<p>Crowe, B. J., Lipkovich, I. A., &amp; Wang, O. (2010). Comparison of several imputation methods for missing baseline data in propensity scores analysis of binary outcome. <em>Pharmaceutical Statistics</em>, <em>9</em>(4), 269–279. <a href="https://doi.org/10.1002/pst.389">https://doi.org/10.1002/pst.389</a></p>
</div>
<div id="ref-dagostino_estimating_2000">
<p>D’Agostino, R. B., &amp; Rubin, D. B. (2000). Estimating and Using Propensity Scores with Partially Missing Data. <em>Journal of the American Statistical Association</em>, <em>95</em>(451), 749. <a href="https://doi.org/10.2307/2669455">https://doi.org/10.2307/2669455</a></p>
</div>
<div id="ref-frangakis_addressing_1999">
<p>Frangakis, C., &amp; Rubin, D. B. (1999). Addressing complications of intention-to-treat analysis in the combined presence of all-or-none treatment-noncompliance and subsequent missing outcomes. <em>Biometrika</em>, <em>86</em>(2), 365–379. <a href="https://doi.org/10.1093/biomet/86.2.365">https://doi.org/10.1093/biomet/86.2.365</a></p>
</div>
<div id="ref-hill_2004">
<p>Hill, J. (2004). <em>Reducing bias in treatment effect estimation in observational studies suffering from missing data</em>. Columbia University Institute for Social &amp; Economic Research &amp; Policy (ISERP).</p>
</div>
<div id="ref-im2016effects">
<p>Im, M. H., Hughes, J. N., Cao, Q., &amp; Kwok, O.-m. (2016). Effects of extracurricular participation during middle school on academic motivation and achievement at grade 9. <em>American Educational Research Journal</em>, <em>53</em>(5), 1343–1375.</p>
</div>
<div id="ref-lee_improving_2009">
<p>Lee, B. K., Lessler, J., &amp; Stuart, E. A. (2009). Improving propensity score weighting using machine learning. <em>Statistics in Medicine</em>, n/a–n/a. <a href="https://doi.org/10.1002/sim.3782">https://doi.org/10.1002/sim.3782</a></p>
</div>
<div id="ref-leyrat_propensity_2019">
<p>Leyrat, C., Seaman, S. R., White, I. R., Douglas, I., Smeeth, L., Kim, J., … Williamson, E. J. (2019). Propensity score analysis with partially observed covariates: How should multiple imputation be used? <em>Statistical Methods in Medical Research</em>, <em>28</em>(1), 3–19. <a href="https://doi.org/10.1177/0962280217713032">https://doi.org/10.1177/0962280217713032</a></p>
</div>
<div id="ref-mitra_comparison_2016">
<p>Mitra, R., &amp; Reiter, J. P. (2016). A comparison of two methods of estimating propensity scores after multiple imputation. <em>Statistical Methods in Medical Research</em>, <em>25</em>(1), 188–204. <a href="https://doi.org/10.1177/0962280212445945">https://doi.org/10.1177/0962280212445945</a></p>
</div>
<div id="ref-mohan_graphical_2013">
<p>Mohan, K., Pearl, J., &amp; Tian, J. (2013). Graphical models for inference with missing data. In C. Burges, L. Bottou, M. Welling, Z. Ghahramani, &amp; K. Q. Weinberger (Eds.), <em>Advances in neural information processing system</em> (pp. 1277–1285). Red Hook, NY: Curran Associates, Inc.</p>
</div>
<div id="ref-murray_multiple_2018">
<p>Murray, J. S. (2018). Multiple Imputation: A Review of Practical and Theoretical Findings. <em>Statistical Science</em>, <em>33</em>(2), 142–159. <a href="https://doi.org/10.1214/18-STS644">https://doi.org/10.1214/18-STS644</a></p>
</div>
<div id="ref-qu_propensity_2009">
<p>Qu, Y., &amp; Lipkovich, I. (2009). Propensity score estimation with missing values using a multiple imputation missingness pattern (MIMP) approach. <em>Statistics in Medicine</em>, <em>28</em>(9), 1402–1414. <a href="https://doi.org/10.1002/sim.3549">https://doi.org/10.1002/sim.3549</a></p>
</div>
<div id="ref-rosenbaum_central_1983">
<p>Rosenbaum, P. R., &amp; Rubin, D. B. (1983). The Central Role of the Propensity Score in Observational Studies for Causal Effects. <em>Biometrika</em>, <em>70</em>(1), 41. <a href="https://doi.org/10.2307/2335942">https://doi.org/10.2307/2335942</a></p>
</div>
<div id="ref-rosenbaum_reducing_1984">
<p>Rosenbaum, P. R., &amp; Rubin, D. B. (1984). Reducing Bias in Observational Studies Using Subclassification on the Propensity Score. <em>Journal of the American Statistical Association</em>, <em>79</em>(387), 516. <a href="https://doi.org/10.2307/2288398">https://doi.org/10.2307/2288398</a></p>
</div>
<div id="ref-rubin_multiple_1987">
<p>Rubin, D. B. (1987). <em>Multiple imputation for nonresponse in surveys</em>. New York: Wiley.</p>
</div>
<div id="ref-stuart_matching_2010">
<p>Stuart, E. A. (2010). Matching Methods for Causal Inference: A Review and a Look Forward. <em>Statistical Science</em>, <em>25</em>(1), 1–21. <a href="https://doi.org/10.1214/09-STS313">https://doi.org/10.1214/09-STS313</a></p>
</div>
<div id="ref-van2018flexible">
<p>van Buuren, S. (2018). <em>Flexible imputation of missing data</em>. Chapman; Hall/CRC.</p>
</div>
<div id="ref-vanB_2011">
<p>van Buuren, S., &amp; Groothuis-Oudshoorn, K. (2011). mice: Multivariate imputation by chained equations in r. <em>Journal of Statistical Software</em>, <em>45</em>(3), 1–67. Retrieved from <a href="http://www.jstatsoft.org/v45/i03/">http://www.jstatsoft.org/v45/i03/</a></p>
</div>
</div>
</div>
