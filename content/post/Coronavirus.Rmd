---
title: "COVID-19"
author: "Megha Joshi"
date: 2020-04-17
categories: ["R"]
tags: ["coronavirus", "COVID-19", "ggplot", "leaflet", "unemployment claims", "time-series", "causal"]

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

In this post, I am analyzing data on COVID-19 cases worldwide. The data that I am analyzing only accounts for reported cases. Due to the lack of availability and accessibility of testing in countries like the US, the numbers may be an underestimate of the actual number of cases, number of deaths, and number of recoveries. The data does not account for any other errors of measurement. 

# Libraries

```{r message = FALSE, warning = FALSE}
library(CausalImpact)
library(tidyverse)
library(maps)
library(ggthemes)
library(jsonlite)
library(leaflet)
library(widgetframe)
library(lubridate)
library(scales)
library(ggrepel)
library(tidyquant)
```


# Read in the Data

I downloaded the data from [here](https://github.com/CSSEGISandData/COVID-19).

```{r, warning = FALSE, message = FALSE}
confirmed <- read_csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv") %>%
  pivot_longer(cols = -c(1:4),
               names_to = "date",
               values_to = "confirmed")

deaths <- read_csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv") %>%
  pivot_longer(cols = -c(1:4),
               names_to = "date",
               values_to = "deaths")

recovered <- read_csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv") %>%
  pivot_longer(cols = -c(1:4),
               names_to = "date",
               values_to = "recoveries")

# Join and Clean 
dat <- left_join(confirmed, deaths) %>%
  left_join(recovered) %>%
  mutate(date = mdy(date),
         lab = paste0("Confirmed: ", confirmed, ", ", "Deaths: ", deaths, ", ", "Recovered: ", recoveries)) %>%
  rename(country_region = `Country/Region`)
```


# Coronavirus Confirmed Cases

```{r}
covid_leaf <- leaflet(data = dat, 
                      options = leafletOptions(minZoom = 1.5)) %>% 
  addProviderTiles(providers$CartoDB.DarkMatter)  %>%
  addCircleMarkers(~Long, ~Lat, 
                   radius = ~confirmed/10000, 
                   label = ~lab, 
                   fillOpacity = .2)

frameWidget(covid_leaf)
```


# Cases by Week

## Confirmed 

```{r, fig.width=10, fig.height=7}
country_dat <- dat %>%
  filter(country_region %in% c("China", "Italy", "Iran", "Korea, South", "Spain", "US")) %>%
  mutate(week = cut(date, "week", start.on.monday = FALSE))

country_dat %>%
  ggplot(aes(x = confirmed/1000, y = week)) +
  geom_bar(stat = "identity", position = "dodge", fill = "blue4") + 
  facet_wrap(~ country_region) +
  labs(y = "", x = "Confirmed Cases (in thousands)") + 
  scale_x_continuous(labels = comma) +
  theme_bw() +
  theme(legend.position = "none")
```

## Deaths

```{r, fig.width=10, fig.height=7}
country_dat %>%
  ggplot(aes(x = deaths/1000, y = week)) +
  geom_bar(stat = "identity", position = "dodge", fill = "red4") + 
  facet_wrap(~ country_region) +
  labs(y = "", x = "Deaths (in thousands)") + 
  scale_x_continuous(labels = comma) +
  theme_bw() +
  theme(legend.position = "none")
```

## Recoveries

```{r, fig.width=10, fig.height=7}
country_dat %>%
  ggplot(aes(x = recoveries/1000, y = week)) +
  geom_bar(stat = "identity", position = "dodge", fill = "green4") + 
  facet_wrap(~ country_region) +
  labs(y = "", x = "Recovered (in thousands)") + 
  scale_x_continuous(labels = comma) +
  theme_bw() +
  theme(legend.position = "none")
```

# Confirmed Cases Trend

```{r, fig.height = 5, fig.width = 7}
sum_dat <- country_dat %>%
  group_by(date, country_region) %>%
  summarize(confirmed = sum(confirmed)) %>%
  ungroup() %>%
  mutate(country_region = if_else(country_region == "Korea, South", "S. Korea", country_region))
  
sum_dat %>%  
  ggplot(aes(x = date, y = confirmed, color = country_region)) +
  geom_line(size = .8) +
  geom_text(data = sum_dat %>% filter(date == last(date)), 
            aes(label = country_region, x = date + .1, 
                y = confirmed, color = country_region), 
            hjust = -.01) +
  scale_y_continuous(labels = comma, breaks = seq(0, 800000, 50000)) +
  xlim(ymd("2020-01-22"), ymd("2020-04-22")) + 
  scale_color_brewer(type = "qual", palette = 2) + 
  labs(x = "", y = "Confirmed Cases", color = "Country") + 
  ggtitle("Confirmed Cases as of April 17, 2020") +
  theme_bw() +
  theme(legend.position = "none")
  
```

# Unemployment Claims in the US

I am retrieving the data from the `tidyquant` package. 

```{r}
icsa_dat <- "ICSA" %>%
  tq_get(get = "economic.data",  
         from = "1967-01-07") %>%
  rename(claims = price)


glimpse(icsa_dat)


icsa_dat %>%
  ggplot(aes(x = date, y = claims)) + 
  geom_line(color = "blue") + 
  scale_y_continuous(labels = comma) +
  labs(x = "Date", y = "Claims") + 
  ggtitle("Unemployment Claims: 1967 to 2020") +
  theme_bw()
```

```{r}
icsa_dat %>%
  mutate(year = year(date)) %>%
  filter(year > 2007) %>%
  ggplot(aes(x = date, y = claims)) + 
  geom_line(color = "blue") + 
  scale_y_continuous(labels = comma) +
  labs(x = "Date", y = "Claims") + 
  ggtitle("Unemployment Claims: 2008 to 2020") +
  theme_bw()
  
```

```{r}
icsa_dat %>%
  mutate(year = year(date)) %>%
  filter(year > 2018) %>%
  ggplot(aes(x = date, y = claims)) + 
  geom_line(color = "blue") + 
  scale_y_continuous(labels = comma) +
  labs(x = "Date", y = "Claims") + 
  ggtitle("Unemployment Claims: 2019 to 2020") +
  theme_bw()
```


# Causal Inference on Impact of COVID-19 Lockdowns on Unemployment Claims

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Sometimes <a href="https://twitter.com/hashtag/causalinference?src=hash&amp;ref_src=twsrc%5Etfw">#causalinference</a> is simple.<br><br>&quot;What&#39;s the immediate causal effect of the <a href="https://twitter.com/hashtag/COVID19?src=hash&amp;ref_src=twsrc%5Etfw">#COVID19</a> lockdowns on unemployment?&quot;<br><br>The answer is &quot;Unprecedented&quot;. <br><br>We know we&#39;re in deep trouble when a time series is all we need. <a href="https://t.co/cXK0wLw3no">https://t.co/cXK0wLw3no</a> <a href="https://t.co/kS4PvVwihM">pic.twitter.com/kS4PvVwihM</a></p>&mdash; Miguel Hern√°n (@_MiguelHernan) <a href="https://twitter.com/_MiguelHernan/status/1244215937978576898?ref_src=twsrc%5Etfw">March 29, 2020</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> 


Below, I use the `CausalImpact` package to run a Bayesian structural time-series analysis. For more information on the package, please see this [vignette](https://cran.r-project.org/web/packages/CausalImpact/vignettes/CausalImpact.html). 

```{r}
dates <- icsa_dat %>% 
  pull(date)

pre_period <- c(dates[1], dates[2776])
post_period <- c(dates[2777], dates[2780])

dat <- icsa_dat %>%
  select(date, y = claims)

impact <- CausalImpact(dat, pre_period, post_period)

# summary(impact, "report")  # this creates the following report :)
```

## Analysis report: CausalImpact

Below is the report generated by `CausalImpact` with some edits by me. 

During the post-COVID lockdown period, the average number of unemployment claims filed was approximately 5.51M. By contrast, in the absence of the lockdown, we would have expected an average number of claims of 0.25M. The 95% interval of this counterfactual prediction is [0.22M, 0.29M]. Subtracting this prediction from the observed response yields an estimate of the causal effect the intervention had on the response variable. This effect is 5.25M with a 95% interval of [5.22M, 5.29M]. 

Summing up the individual data points during the post-lockdown period, the response variable had an overall value of 22.03M. By contrast, had the intervention not taken place, we would have expected a sum of 1.01M. The 95% interval of this prediction is [0.88M, 1.15M].

The above results are given in terms of absolute numbers. In relative terms, the number of unemployment claims showed an increase of +2073%. The 95% interval of this percentage is [+2059%, +2086%].

The probability of obtaining this effect by chance is very small (Bayesian one-sided tail-area probability p = 0.001). This means the causal effect can be considered statistically significant.


